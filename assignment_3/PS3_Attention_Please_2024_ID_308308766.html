<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>PS3_Attention_Please_2024_ID_308308766</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Neural-Machine-Translation-with-Attention">Neural Machine Translation with Attention<a class="anchor-link" href="#Neural-Machine-Translation-with-Attention"></a></h1><p>Advanced Learning Fall 2024.<br/>
Last updated: 2025-01-12</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>For SUBMISSION:</p>
<p>Please upload the complete and executed <code>ipynb</code> to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.</p>
<pre><code>STUDENT ID: 308308766
</code></pre>
<pre><code>STUDENT GIT LINK: https://github.com/Nitzan93/52025-Course/tree/main/assignment_3
</code></pre>
<p>In Addition, don't forget to add your ID to the files, and upload to moodle the html version:</p>
<p><code>PS3_Attention_2024_ID_[000000000].html</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this problem set we are going to jump into the depths of <code>seq2seq</code> and <code>attention</code> and build a couple of PyTorch translation mechanisms with some  twists.</p>
<ul>
<li>Part 1 consists of a somewhat unorthodox <code>seq2seq</code> model for simple arithmetics</li>
<li>Part 2 consists of an <code>seq2seq - attention</code> language translation model. We will use it for Hebrew and English.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>A <strong>seq2seq</strong> model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.</p>
<p>Here's a breakdown of how <code>seq2seq</code> models work:</p>
<ul>
<li><p>The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.</p>
</li>
<li><p>information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.</p>
</li>
<li><p>Attention mechanism (optional): Some <code>seq2seq</code> models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.</p>
</li>
</ul>
<p><code>seq2seq</code> models are used in many natural language processing (NLP) tasks.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>imports: (feel free to add)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># from __future__ import unicode_literals, print_function, division</span>
<span class="c1"># from io import open</span>
<span class="c1"># import unicodedata</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-1:-Seq2Seq-Arithmetic-model">Part 1: Seq2Seq Arithmetic model<a class="anchor-link" href="#Part-1:-Seq2Seq-Arithmetic-model"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Using RNN <code>seq2seq</code> model to "learn" simple arithmetics!</strong></p>
<blockquote>
<p>Given the string "54-7", the model should return a prediction: "47".<br/>
Given the string "10+20", the model should return a prediction: "30".</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Watch Lukas Biewald's short <a href="https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1">video</a> explaining <code>seq2seq</code> models and his toy application (somewhat outdated).</li>
<li>You can find the code for his example <a href="https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py">here</a>.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.1) Using Lukas' code, implement a <code>seq2seq</code> network that can learn how to solve <strong>addition AND substraction</strong> of two numbers of maximum length of 4, using the following steps (similar to the example):</p>
<ul>
<li>Generate data; X: queries (two numbers), and Y: answers</li>
<li>One-hot encode X and Y,</li>
<li>Build a <code>seq2seq</code> network (with LSTM, RepeatVector, and TimeDistributed layers)</li>
<li>Train the model.</li>
<li>While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.</li>
</ul>
<p>Notes:</p>
<ul>
<li>The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the "correct" output - this will help you fix the unsupported "model.predict_classes".</li>
<li>Please use the parameters in the code cell below to train the model.</li>
<li>Instead of using a <code>wandb.config</code> object, please use a simple dictionary instead.</li>
<li>You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.</li>
<li>Extra credit if you can implement the network in PyTorch (this is not difficult).</li>
<li>Extra credit if you are able to significantly improve the model.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Keras"><strong>Keras</strong><a class="anchor-link" href="#Keras"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">RepeatVector</span><span class="p">,</span> <span class="n">Dense</span>


<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>

<span class="n">maxlen</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s2">"0123456789+- "</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"char_to_index"</span><span class="p">:</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
    <span class="s2">"index_to_char"</span><span class="p">:</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""One-hot encode the sequence."""</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Decode one-hot encoded sequence."""</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">seq</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"index_to_char"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>

<span class="c1"># Data Generation</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">params</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">"+"</span><span class="p">,</span> <span class="s2">"-"</span><span class="p">])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">operation</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>  <span class="c1"># Calculate the result</span>
    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>  <span class="c1"># Padded to maxlen</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Padded to output length</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">answers</span><span class="p">)):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

<span class="c1"># Train / Test Split</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Model Definition</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">RepeatVector</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>

<span class="c1"># Training</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">params</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
    <span class="c1"># Test predictions on random samples</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | True: </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Pred: </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">26s</span> 57ms/step - accuracy: 0.2173 - loss: 2.2427 - val_accuracy: 0.2785 - val_loss: 1.9883
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">1s</span> 534ms/step
Q: 876-2779 | True: -1903 | Pred: -222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 6521+9269 | True: 15790 | Pred: 1002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 863-6340 | True: -5477 | Pred: -222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 54ms/step
Q: 621-6562 | True: -5941 | Pred: -222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 8333-4169 | True: 4164 | Pred: -22
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 9013-3191 | True: 5822 | Pred: 222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 6323+9541 | True: 15864 | Pred: 1002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 5475-7740 | True: -2265 | Pred: -222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 5545+2995 | True: 8540 | Pred: 1002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 7625+4155 | True: 11780 | Pred: 1002
Epoch 2/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.2856 - loss: 1.9536 - val_accuracy: 0.3123 - val_loss: 1.8640
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6330+7595 | True: 13925 | Pred: 14177
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1305-4237 | True: -2932 | Pred: -213
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 298+9139 | True: 9437 | Pred: 7911
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2503+372 | True: 2875 | Pred: 5911
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6559+2558 | True: 9117 | Pred: 1011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 669+9344 | True: 10013 | Pred: 7011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5650+7133 | True: 12783 | Pred: 12111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 5476-6752 | True: -1276 | Pred: -133
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3614+2949 | True: 6563 | Pred: 1011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3051-6949 | True: -3898 | Pred: -133
Epoch 3/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.3170 - loss: 1.8402 - val_accuracy: 0.3291 - val_loss: 1.7869
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7298-7504 | True: -206 | Pred: -10
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6019+4770 | True: 10789 | Pred: 11998
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8419-6143 | True: 2276 | Pred: 5087
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5087-3171 | True: 1916 | Pred: 3087
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5820+9173 | True: 14993 | Pred: 14099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 470+4627 | True: 5097 | Pred: 5911
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 184-1043 | True: -859 | Pred: -1077
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8710+8075 | True: 16785 | Pred: 17999
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 8683-9684 | True: -1001 | Pred: -10
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6319+958 | True: 7277 | Pred: 1007
Epoch 4/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.3416 - loss: 1.7642 - val_accuracy: 0.3469 - val_loss: 1.7417
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 9108-2480 | True: 6628 | Pred: 4611
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5900-4109 | True: 1791 | Pred: 116
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 4761-2577 | True: 2184 | Pred: 116
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8539+1677 | True: 10216 | Pred: 1002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5648-1921 | True: 3727 | Pred: 2166
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 8872+2619 | True: 11491 | Pred: 11066
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1014+7573 | True: 8587 | Pred: 8046
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 5611-1032 | True: 4579 | Pred: 3881
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 622-8353 | True: -7731 | Pred: -6383
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6317-9097 | True: -2780 | Pred: -3333
Epoch 5/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.3566 - loss: 1.7112 - val_accuracy: 0.3558 - val_loss: 1.7035
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4259+6238 | True: 10497 | Pred: 9001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 976-7952 | True: -6976 | Pred: -7477
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7745-173 | True: 7572 | Pred: 7711
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2553-9526 | True: -6973 | Pred: -7714
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7926-9478 | True: -1552 | Pred: -1088
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8201-1986 | True: 6215 | Pred: 4411
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 4730+7420 | True: 12150 | Pred: 11912
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6687+158 | True: 6845 | Pred: 4111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9330+3316 | True: 12646 | Pred: 11912
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 795-5311 | True: -4516 | Pred: -5447
Epoch 6/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.3729 - loss: 1.6615 - val_accuracy: 0.3837 - val_loss: 1.6407
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7591+8801 | True: 16392 | Pred: 16422
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 3592+3406 | True: 6998 | Pred: 6853
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 3040+6286 | True: 9326 | Pred: 9001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9707-922 | True: 8785 | Pred: 7888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 603-9698 | True: -9095 | Pred: -8910
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 9588+9411 | True: 18999 | Pred: 18762
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 6903-371 | True: 6532 | Pred: 6811
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 9623-6291 | True: 3332 | Pred: 3885
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 6740-6719 | True: 21 | Pred: 112
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 447-1733 | True: -1286 | Pred: -1044
Epoch 7/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.3851 - loss: 1.6330 - val_accuracy: 0.3980 - val_loss: 1.5985
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3144-948 | True: 2196 | Pred: -14
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7080-2055 | True: 5025 | Pred: 4811
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 191-4560 | True: -4369 | Pred: -4028
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 2967-7544 | True: -4577 | Pred: -4028
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1372+6934 | True: 8306 | Pred: 8944
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 3923+6522 | True: 10445 | Pred: 10622
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8789-5971 | True: 2818 | Pred: 2282
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9569-7080 | True: 2489 | Pred: 2282
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 9791-311 | True: 9480 | Pred: 7882
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8967+9301 | True: 18268 | Pred: 18598
Epoch 8/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.3968 - loss: 1.6024 - val_accuracy: 0.3809 - val_loss: 1.6119
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7304-490 | True: 6814 | Pred: 6225
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9791-311 | True: 9480 | Pred: 7786
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 513+1592 | True: 2105 | Pred: 3211
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 9117-7804 | True: 1313 | Pred: 125
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6595-8442 | True: -1847 | Pred: -2333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4276+2080 | True: 6356 | Pred: 6333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 4312+7871 | True: 12183 | Pred: 12888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9750-5003 | True: 4747 | Pred: 4325
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4843-6512 | True: -1669 | Pred: -1753
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8521-1296 | True: 7225 | Pred: 6226
Epoch 9/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 61ms/step - accuracy: 0.4018 - loss: 1.5837 - val_accuracy: 0.4108 - val_loss: 1.5656
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6976-6461 | True: 515 | Pred: 112
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6218+3151 | True: 9369 | Pred: 9038
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7818-4747 | True: 3071 | Pred: 3349
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8189-816 | True: 7373 | Pred: 7789
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4937-4112 | True: 825 | Pred: 122
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6106+343 | True: 6449 | Pred: 5734
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6330+5690 | True: 12020 | Pred: 11273
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7995-6218 | True: 1777 | Pred: 2249
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5353-1537 | True: 3816 | Pred: 3341
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 7382-7676 | True: -294 | Pred: -10
Epoch 10/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 57ms/step - accuracy: 0.4098 - loss: 1.5642 - val_accuracy: 0.4066 - val_loss: 1.5629
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4450+9440 | True: 13890 | Pred: 13383
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5017-4162 | True: 855 | Pred: 11
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6773-599 | True: 6174 | Pred: 5179
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 8099-8354 | True: -255 | Pred: -100
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3496-1068 | True: 2428 | Pred: 2239
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5642-6375 | True: -733 | Pred: -103
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4423-9779 | True: -5356 | Pred: -5444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3569+6310 | True: 9879 | Pred: 9011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 6758+4268 | True: 11026 | Pred: 11813
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 9231+9215 | True: 18446 | Pred: 17188
Epoch 11/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 62ms/step - accuracy: 0.4149 - loss: 1.5472 - val_accuracy: 0.4251 - val_loss: 1.5284
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 8226+9240 | True: 17466 | Pred: 17988
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 3173-9432 | True: -6259 | Pred: -6655
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 5031-1353 | True: 3678 | Pred: 3381
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 50ms/step
Q: 2513+6993 | True: 9506 | Pred: 9011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 54ms/step
Q: 5004-6655 | True: -1651 | Pred: -1513
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 1142-3340 | True: -2198 | Pred: -2383
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 4530+8475 | True: 13005 | Pred: 12888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 860+949 | True: 1809 | Pred: 8532
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 323+8225 | True: 8548 | Pred: 8833
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 2419+3862 | True: 6281 | Pred: 6111
Epoch 12/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.4224 - loss: 1.5281 - val_accuracy: 0.4220 - val_loss: 1.5284
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1545+378 | True: 1923 | Pred: 2223
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8666-3470 | True: 5196 | Pred: 5355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4756+4123 | True: 8879 | Pred: 8931
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6106+343 | True: 6449 | Pred: 5233
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2319-3080 | True: -761 | Pred: -105
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5545+2995 | True: 8540 | Pred: 8922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 1944+3732 | True: 5676 | Pred: 5553
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2516-245 | True: 2271 | Pred: 2335
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 9425+8820 | True: 18245 | Pred: 18555
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 3420-145 | True: 3275 | Pred: 3235
Epoch 13/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.4251 - loss: 1.5181 - val_accuracy: 0.4283 - val_loss: 1.5088
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3244-6841 | True: -3597 | Pred: -3000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5332-9174 | True: -3842 | Pred: -3000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1295-1213 | True: 82 | Pred: -0
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 1714-3419 | True: -1705 | Pred: -1033
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5731+8940 | True: 14671 | Pred: 14500
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1862-9644 | True: -7782 | Pred: -7100
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3978+531 | True: 4509 | Pred: 6286
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 3563-7728 | True: -4165 | Pred: -4000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4845+4549 | True: 9394 | Pred: 9400
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8192+2053 | True: 10245 | Pred: 10008
Epoch 14/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 61ms/step - accuracy: 0.4267 - loss: 1.5113 - val_accuracy: 0.4308 - val_loss: 1.4947
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1096+1832 | True: 2928 | Pred: 3889
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 7594-443 | True: 7151 | Pred: 6881
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7151-3506 | True: 3645 | Pred: 3355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7613-4863 | True: 2750 | Pred: 2655
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1888-5896 | True: -4008 | Pred: -3588
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5689-6802 | True: -1113 | Pred: -1055
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1615-1003 | True: 612 | Pred: 100
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6189+271 | True: 6460 | Pred: 4182
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7783+5442 | True: 13225 | Pred: 13819
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 683-5356 | True: -4673 | Pred: -4148
Epoch 15/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 57ms/step - accuracy: 0.4339 - loss: 1.4943 - val_accuracy: 0.4296 - val_loss: 1.4954
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 409+4349 | True: 4758 | Pred: 4001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 9796-5489 | True: 4307 | Pred: 4000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3900+3214 | True: 7114 | Pred: 7200
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4151+6745 | True: 10896 | Pred: 10922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 809-4976 | True: -4167 | Pred: -4778
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 5471-5163 | True: 308 | Pred: 120
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 322-5949 | True: -5627 | Pred: -5800
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 2325+1093 | True: 3418 | Pred: 3600
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 4935-6927 | True: -1992 | Pred: -1253
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 8260+7237 | True: 15497 | Pred: 15020
Epoch 16/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 61ms/step - accuracy: 0.4384 - loss: 1.4842 - val_accuracy: 0.4294 - val_loss: 1.4985
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3347+4236 | True: 7583 | Pred: 7554
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4156+3387 | True: 7543 | Pred: 7754
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9458-1037 | True: 8421 | Pred: 7003
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2578-5658 | True: -3080 | Pred: -3079
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 9443+5368 | True: 14811 | Pred: 14222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8292+8031 | True: 16323 | Pred: 16155
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 1519+7614 | True: 9133 | Pred: 8244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3203+5777 | True: 8980 | Pred: 8204
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 6499+3566 | True: 10065 | Pred: 9002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 7254-4355 | True: 2899 | Pred: 2763
Epoch 17/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.4403 - loss: 1.4783 - val_accuracy: 0.4308 - val_loss: 1.4946
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1892+5885 | True: 7777 | Pred: 7707
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8058-3926 | True: 4132 | Pred: 4001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 2379-4315 | True: -1936 | Pred: -1750
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1238+7241 | True: 8479 | Pred: 8009
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5731-4180 | True: 1551 | Pred: 1015
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8222-906 | True: 7316 | Pred: 7075
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8505+6123 | True: 14628 | Pred: 14170
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 5735-8819 | True: -3084 | Pred: -2215
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 2875+6977 | True: 9852 | Pred: 9700
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6545-5344 | True: 1201 | Pred: 1015
Epoch 18/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 62ms/step - accuracy: 0.4436 - loss: 1.4663 - val_accuracy: 0.4409 - val_loss: 1.4696
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3704-4194 | True: -490 | Pred: -102
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1228-3520 | True: -2292 | Pred: -2288
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5523-3887 | True: 1636 | Pred: 1220
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1476+5710 | True: 7186 | Pred: 7222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1497-3583 | True: -2086 | Pred: -1753
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 4663+1622 | True: 6285 | Pred: 6952
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4638-1451 | True: 3187 | Pred: 3321
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 1525-9003 | True: -7478 | Pred: -7102
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8540+5844 | True: 14384 | Pred: 14755
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 1441+1813 | True: 3254 | Pred: 3222
Epoch 19/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.4466 - loss: 1.4619 - val_accuracy: 0.4356 - val_loss: 1.4765
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2691+9922 | True: 12613 | Pred: 12729
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6507-6664 | True: -157 | Pred: -14
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 517-7209 | True: -6692 | Pred: -6223
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8007-4602 | True: 3405 | Pred: 3955
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1582-2584 | True: -1002 | Pred: -123
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 9113+3957 | True: 13070 | Pred: 12800
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 685+6563 | True: 7248 | Pred: 7202
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2485+2798 | True: 5283 | Pred: 5099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3858+8503 | True: 12361 | Pred: 12222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6881-8623 | True: -1742 | Pred: -1252
Epoch 20/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.4492 - loss: 1.4559 - val_accuracy: 0.4474 - val_loss: 1.4494
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 49ms/step
Q: 9475-302 | True: 9173 | Pred: 8884
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 52ms/step
Q: 2590+7899 | True: 10489 | Pred: 10211
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 52ms/step
Q: 7054+1430 | True: 8484 | Pred: 8101
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 5865+5226 | True: 11091 | Pred: 11111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 9418+4203 | True: 13621 | Pred: 13615
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 9013-3191 | True: 5822 | Pred: 5018
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 9342+1366 | True: 10708 | Pred: 10855
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 5306-8812 | True: -3506 | Pred: -3511
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 59ms/step
Q: 2913-2249 | True: 664 | Pred: 516
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 66ms/step
Q: 1980-2073 | True: -93 | Pred: -144
Epoch 21/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 62ms/step - accuracy: 0.4526 - loss: 1.4463 - val_accuracy: 0.4486 - val_loss: 1.4429
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8418-247 | True: 8171 | Pred: 7873
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 3864+7239 | True: 11103 | Pred: 11212
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 8952-609 | True: 8343 | Pred: 7996
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2720-4115 | True: -1395 | Pred: -1555
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6982+8028 | True: 15010 | Pred: 15475
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 91-1220 | True: -1129 | Pred: -1743
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6110-5317 | True: 793 | Pred: 115
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 1014+7573 | True: 8587 | Pred: 8999
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 1304-696 | True: 608 | Pred: 122
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 5232+4170 | True: 9402 | Pred: 9544
Epoch 22/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 58ms/step - accuracy: 0.4557 - loss: 1.4383 - val_accuracy: 0.4532 - val_loss: 1.4328
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2296+9611 | True: 11907 | Pred: 11585
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3391-221 | True: 3170 | Pred: 3389
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 9036-7760 | True: 1276 | Pred: 1011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 323+8225 | True: 8548 | Pred: 8333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3718+9043 | True: 12761 | Pred: 12885
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1677-7877 | True: -6200 | Pred: -6808
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 3060-9799 | True: -6739 | Pred: -6808
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8072-2144 | True: 5928 | Pred: 5021
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1922-9510 | True: -7588 | Pred: -7505
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 515+1684 | True: 2199 | Pred: 2901
Epoch 23/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.4611 - loss: 1.4252 - val_accuracy: 0.4508 - val_loss: 1.4357
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 177+5091 | True: 5268 | Pred: 3552
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 5226+9194 | True: 14420 | Pred: 14662
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 2188+7360 | True: 9548 | Pred: 9602
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 1026-1540 | True: -514 | Pred: -123
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 4365-3732 | True: 633 | Pred: 122
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9296-5281 | True: 4015 | Pred: 4355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 3991+2819 | True: 6810 | Pred: 6552
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 8552+5619 | True: 14171 | Pred: 14860
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 1459+9457 | True: 10916 | Pred: 10869
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 695+8869 | True: 9564 | Pred: 9742
Epoch 24/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 61ms/step - accuracy: 0.4615 - loss: 1.4177 - val_accuracy: 0.4530 - val_loss: 1.4409
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3416-7847 | True: -4431 | Pred: -3331
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3546-1699 | True: 1847 | Pred: 2266
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 772+5153 | True: 5925 | Pred: 6113
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9222-1335 | True: 7887 | Pred: 7113
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6841+9851 | True: 16692 | Pred: 16693
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9189+3431 | True: 12620 | Pred: 12922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3498-5706 | True: -2208 | Pred: -2888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7621-3715 | True: 3906 | Pred: 3335
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 7537-7136 | True: 401 | Pred: 118
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8971+8831 | True: 17802 | Pred: 17674
Epoch 25/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.4644 - loss: 1.4100 - val_accuracy: 0.4612 - val_loss: 1.4060
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9527+6332 | True: 15859 | Pred: 15799
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3087+2055 | True: 5142 | Pred: 5959
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 9975-8337 | True: 1638 | Pred: 1005
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 9897-6768 | True: 3129 | Pred: 3005
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6901-9117 | True: -2216 | Pred: -2277
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2431+85 | True: 2516 | Pred: 3228
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8956+1486 | True: 10442 | Pred: 10251
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5275-4598 | True: 677 | Pred: 304
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4756+4123 | True: 8879 | Pred: 8807
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 2405-669 | True: 1736 | Pred: 1000
Epoch 26/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.4696 - loss: 1.3973 - val_accuracy: 0.4653 - val_loss: 1.3946
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 1725-2886 | True: -1161 | Pred: -103
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 1433-8392 | True: -6959 | Pred: -6333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 5097+9704 | True: 14801 | Pred: 14873
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 6733-1971 | True: 4762 | Pred: 4635
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 5473+9247 | True: 14720 | Pred: 14877
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 4342-7805 | True: -3463 | Pred: -3566
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 3796+7865 | True: 11661 | Pred: 11678
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8222-906 | True: 7316 | Pred: 7083
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 2916+8061 | True: 10977 | Pred: 10973
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 226+4267 | True: 4493 | Pred: 4553
Epoch 27/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.4741 - loss: 1.3852 - val_accuracy: 0.4686 - val_loss: 1.3863
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4632-4467 | True: 165 | Pred: 301
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8284+36 | True: 8320 | Pred: 9658
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1621-2322 | True: -701 | Pred: -803
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4804+3257 | True: 8061 | Pred: 8036
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6786+5679 | True: 12465 | Pred: 12592
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4411+8065 | True: 12476 | Pred: 12972
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8091-9332 | True: -1241 | Pred: -1200
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3494-1173 | True: 2321 | Pred: 2265
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1044+3066 | True: 4110 | Pred: 4224
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8183+9374 | True: 17557 | Pred: 17423
Epoch 28/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 64ms/step - accuracy: 0.4813 - loss: 1.3689 - val_accuracy: 0.4737 - val_loss: 1.3749
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4759+5866 | True: 10625 | Pred: 10577
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1433-8392 | True: -6959 | Pred: -6262
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9635+9766 | True: 19401 | Pred: 19448
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 970+2788 | True: 3758 | Pred: 3770
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 885+31 | True: 916 | Pred: 804
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1543-3470 | True: -1927 | Pred: -1903
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 2154-5321 | True: -3167 | Pred: -3029
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 761-5765 | True: -5004 | Pred: -4542
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 1664-679 | True: 985 | Pred: 132
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 848-6806 | True: -5958 | Pred: -5850
Epoch 29/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 58ms/step - accuracy: 0.4824 - loss: 1.3657 - val_accuracy: 0.4748 - val_loss: 1.3686
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4183+6318 | True: 10501 | Pred: 10316
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6201+7230 | True: 13431 | Pred: 13363
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6510-6484 | True: 26 | Pred: -1
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4262-5650 | True: -1388 | Pred: -1350
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2225+4189 | True: 6414 | Pred: 6613
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 9209+3883 | True: 13092 | Pred: 13199
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 591-6579 | True: -5988 | Pred: -5255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5001-1926 | True: 3075 | Pred: 3991
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 5630-5416 | True: 214 | Pred: 316
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 3852-6266 | True: -2414 | Pred: -2226
Epoch 30/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 64ms/step - accuracy: 0.4905 - loss: 1.3453 - val_accuracy: 0.4863 - val_loss: 1.3433
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 8755-5001 | True: 3754 | Pred: 3355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9202-609 | True: 8593 | Pred: 8006
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9044+9172 | True: 18216 | Pred: 18464
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 1842-9487 | True: -7645 | Pred: -7105
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 4343+1068 | True: 5411 | Pred: 5656
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 8333-4169 | True: 4164 | Pred: 4055
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 6925+1924 | True: 8849 | Pred: 8701
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 3246+8326 | True: 11572 | Pred: 11565
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 6931-4828 | True: 2103 | Pred: 2175
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 1811+5374 | True: 7185 | Pred: 7935
Epoch 31/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.4939 - loss: 1.3340 - val_accuracy: 0.4830 - val_loss: 1.3452
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6537-3051 | True: 3486 | Pred: 3662
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9707-922 | True: 8785 | Pred: 8289
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2740+9568 | True: 12308 | Pred: 12349
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 9697-1297 | True: 8400 | Pred: 8289
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5545-5892 | True: -347 | Pred: -544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7498+5394 | True: 12892 | Pred: 12872
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 1841+2402 | True: 4243 | Pred: 4299
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 4436+6874 | True: 11310 | Pred: 11242
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3153+5506 | True: 8659 | Pred: 8672
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 1833-3521 | True: -1688 | Pred: -1753
Epoch 32/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.4975 - loss: 1.3201 - val_accuracy: 0.4935 - val_loss: 1.3188
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 6511-6456 | True: 55 | Pred: -2
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 5475-7740 | True: -2265 | Pred: -2316
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6031+5944 | True: 11975 | Pred: 11900
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 283+7461 | True: 7744 | Pred: 7906
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 5895+3391 | True: 9286 | Pred: 9200
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4142-3124 | True: 1018 | Pred: 1011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6356-7255 | True: -899 | Pred: -906
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 7441-9126 | True: -1685 | Pred: -1515
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1012-5482 | True: -4470 | Pred: -4041
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5247-9992 | True: -4745 | Pred: -4651
Epoch 33/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 66ms/step - accuracy: 0.5068 - loss: 1.2986 - val_accuracy: 0.4986 - val_loss: 1.3111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4066+3059 | True: 7125 | Pred: 7207
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6278-1147 | True: 5131 | Pred: 5081
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 2330-8535 | True: -6205 | Pred: -6332
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6862+1010 | True: 7872 | Pred: 7887
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 3677-1625 | True: 2052 | Pred: 2280
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 81+4292 | True: 4373 | Pred: 3488
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5603-9024 | True: -3421 | Pred: -3226
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1869+675 | True: 2544 | Pred: 2488
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2909+5284 | True: 8193 | Pred: 8037
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6974-1164 | True: 5810 | Pred: 5681
Epoch 34/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 61ms/step - accuracy: 0.5109 - loss: 1.2866 - val_accuracy: 0.5086 - val_loss: 1.2867
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3194-799 | True: 2395 | Pred: 2391
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1974+5627 | True: 7601 | Pred: 7591
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 1979-6335 | True: -4356 | Pred: -4341
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7560+7880 | True: 15440 | Pred: 15455
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6863-9636 | True: -2773 | Pred: -2011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 7104+599 | True: 7703 | Pred: 8991
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 2451-6229 | True: -3778 | Pred: -3981
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 7674-8085 | True: -411 | Pred: -600
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 6355-433 | True: 5922 | Pred: 5111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 7649-1533 | True: 6116 | Pred: 5000
Epoch 35/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 65ms/step - accuracy: 0.5180 - loss: 1.2695 - val_accuracy: 0.5148 - val_loss: 1.2646
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 2319-3080 | True: -761 | Pred: -804
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 3900+3214 | True: 7114 | Pred: 7107
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 7192+6976 | True: 14168 | Pred: 14075
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 3892-5522 | True: -1630 | Pred: -1515
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 57ms/step
Q: 7766-133 | True: 7633 | Pred: 7704
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 4482-972 | True: 3510 | Pred: 3581
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 8020-6087 | True: 1933 | Pred: 1015
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 2569-2305 | True: 264 | Pred: 104
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 3355+5941 | True: 9296 | Pred: 9220
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 6338-4514 | True: 1824 | Pred: 1815
Epoch 36/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.5269 - loss: 1.2466 - val_accuracy: 0.5145 - val_loss: 1.2608
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2398-9450 | True: -7052 | Pred: -7155
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 3056+1845 | True: 4901 | Pred: 5995
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8724-2409 | True: 6315 | Pred: 6355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9871+8915 | True: 18786 | Pred: 18791
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 1869+8265 | True: 10134 | Pred: 10279
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8907-1170 | True: 7737 | Pred: 7557
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8724-2409 | True: 6315 | Pred: 6355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 9228-7343 | True: 1885 | Pred: 1815
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 6312-4866 | True: 1446 | Pred: 1557
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 9071+9211 | True: 18282 | Pred: 18344
Epoch 37/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.5338 - loss: 1.2283 - val_accuracy: 0.5286 - val_loss: 1.2333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5333-7035 | True: -1702 | Pred: -1716
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8764+1426 | True: 10190 | Pred: 10107
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6971-1243 | True: 5728 | Pred: 5607
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 1802-6988 | True: -5186 | Pred: -5801
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8968-8429 | True: 539 | Pred: 659
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5796+5161 | True: 10957 | Pred: 10908
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3846+5944 | True: 9790 | Pred: 9802
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5326-8192 | True: -2866 | Pred: -2866
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 2588-9549 | True: -6961 | Pred: -7184
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5575+2696 | True: 8271 | Pred: 8357
Epoch 38/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 66ms/step - accuracy: 0.5402 - loss: 1.2125 - val_accuracy: 0.5397 - val_loss: 1.2121
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 2591-1461 | True: 1130 | Pred: 1014
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6791+331 | True: 7122 | Pred: 7066
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 2219-5422 | True: -3203 | Pred: -3219
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 7017-3702 | True: 3315 | Pred: 3238
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 1353-4183 | True: -2830 | Pred: -2888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3203+5777 | True: 8980 | Pred: 9002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7489-9420 | True: -1931 | Pred: -1911
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 456+4067 | True: 4523 | Pred: 4611
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 4740-6757 | True: -2017 | Pred: -2061
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6158+4378 | True: 10536 | Pred: 10613
Epoch 39/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 66ms/step - accuracy: 0.5496 - loss: 1.1904 - val_accuracy: 0.5410 - val_loss: 1.2011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1599+9475 | True: 11074 | Pred: 11108
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6906-6153 | True: 753 | Pred: 448
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5573-4581 | True: 992 | Pred: 101
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8954-7411 | True: 1543 | Pred: 1581
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3265-1017 | True: 2248 | Pred: 2388
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 470+9665 | True: 10135 | Pred: 10284
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7371+8210 | True: 15581 | Pred: 15553
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5448+314 | True: 5762 | Pred: 5611
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 9743-8307 | True: 1436 | Pred: 1465
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5809-1804 | True: 4005 | Pred: 3046
Epoch 40/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 64ms/step - accuracy: 0.5557 - loss: 1.1772 - val_accuracy: 0.5480 - val_loss: 1.1858
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 8581+1632 | True: 10213 | Pred: 10190
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2893-4215 | True: -1322 | Pred: -1355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1876-8935 | True: -7059 | Pred: -7906
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9985-8891 | True: 1094 | Pred: 1099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 1154+2683 | True: 3837 | Pred: 3999
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2351-4388 | True: -2037 | Pred: -2069
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 6230+6588 | True: 12818 | Pred: 12872
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1123+9723 | True: 10846 | Pred: 10835
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2020+6611 | True: 8631 | Pred: 7699
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2065-7791 | True: -5726 | Pred: -5766
Epoch 41/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">24s</span> 67ms/step - accuracy: 0.5606 - loss: 1.1615 - val_accuracy: 0.5534 - val_loss: 1.1729
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8305-8917 | True: -612 | Pred: -677
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8406+9993 | True: 18399 | Pred: 18364
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 7164+4968 | True: 12132 | Pred: 12184
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8348-2663 | True: 5685 | Pred: 5664
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8654-7193 | True: 1461 | Pred: 1483
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 4854-9054 | True: -4200 | Pred: -4355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9813+3002 | True: 12815 | Pred: 12846
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8027+5242 | True: 13269 | Pred: 13344
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 1793-3164 | True: -1371 | Pred: -1213
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6310-6572 | True: -262 | Pred: -332
Epoch 42/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 63ms/step - accuracy: 0.5679 - loss: 1.1476 - val_accuracy: 0.5592 - val_loss: 1.1628
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6201+7230 | True: 13431 | Pred: 13413
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2081+8848 | True: 10929 | Pred: 10979
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5059-591 | True: 4468 | Pred: 4339
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6670+8935 | True: 15605 | Pred: 15655
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4998+9623 | True: 14621 | Pred: 14653
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 8482-8514 | True: -32 | Pred: -14
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 930+6943 | True: 7873 | Pred: 8792
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4149-6141 | True: -1992 | Pred: -1943
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8802-9010 | True: -208 | Pred: -343
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 1269+9498 | True: 10767 | Pred: 10732
Epoch 43/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">24s</span> 67ms/step - accuracy: 0.5725 - loss: 1.1372 - val_accuracy: 0.5596 - val_loss: 1.1609
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5894+7767 | True: 13661 | Pred: 13633
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 7133-2945 | True: 4188 | Pred: 4230
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 5073-2980 | True: 2093 | Pred: 2136
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4893-1333 | True: 3560 | Pred: 3533
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 1667+1248 | True: 2915 | Pred: 2996
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 546+6737 | True: 7283 | Pred: 7146
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 7411-8595 | True: -1184 | Pred: -1118
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4955+8417 | True: 13372 | Pred: 13355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 8512-5890 | True: 2622 | Pred: 2666
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7808+8261 | True: 16069 | Pred: 16003
Epoch 44/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 67ms/step - accuracy: 0.5754 - loss: 1.1293 - val_accuracy: 0.5588 - val_loss: 1.1565
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 3371-4248 | True: -877 | Pred: -903
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6947+6002 | True: 12949 | Pred: 12972
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 2942+3397 | True: 6339 | Pred: 6379
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9474+7414 | True: 16888 | Pred: 16877
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 8603-5657 | True: 2946 | Pred: 2975
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 308-419 | True: -111 | Pred: -11
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 2546+7273 | True: 9819 | Pred: 9782
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4462+5677 | True: 10139 | Pred: 10172
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7926-9419 | True: -1493 | Pred: -1515
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 7612+8101 | True: 15713 | Pred: 15777
Epoch 45/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">24s</span> 68ms/step - accuracy: 0.5784 - loss: 1.1213 - val_accuracy: 0.5704 - val_loss: 1.1340
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6213+2417 | True: 8630 | Pred: 8655
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9387+6985 | True: 16372 | Pred: 16394
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2137-9339 | True: -7202 | Pred: -7191
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9661+5844 | True: 15505 | Pred: 15495
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 198+8274 | True: 8472 | Pred: 8389
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 128+9674 | True: 9802 | Pred: 9888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9485-3854 | True: 5631 | Pred: 5628
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 440+2461 | True: 2901 | Pred: 3952
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 2590+7899 | True: 10489 | Pred: 10408
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 3208+7908 | True: 11116 | Pred: 11125
Epoch 46/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">24s</span> 67ms/step - accuracy: 0.5841 - loss: 1.1090 - val_accuracy: 0.5730 - val_loss: 1.1263
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 795-5311 | True: -4516 | Pred: -4405
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6848+2232 | True: 9080 | Pred: 9102
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 7306+188 | True: 7494 | Pred: 7583
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 71ms/step
Q: 3120+1969 | True: 5089 | Pred: 5001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 49ms/step
Q: 3581-2263 | True: 1318 | Pred: 1394
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 2488-9501 | True: -7013 | Pred: -7066
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 3329+5219 | True: 8548 | Pred: 8544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 5476-6752 | True: -1276 | Pred: -1223
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 2323+2999 | True: 5322 | Pred: 5221
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 1821-6882 | True: -5061 | Pred: -5036
Epoch 47/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 65ms/step - accuracy: 0.5856 - loss: 1.1022 - val_accuracy: 0.5648 - val_loss: 1.1390
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 2225+4189 | True: 6414 | Pred: 6315
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 7828+5634 | True: 13462 | Pred: 13411
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 8826+7092 | True: 15918 | Pred: 15988
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 4983+8634 | True: 13617 | Pred: 13615
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 5271+6251 | True: 11522 | Pred: 11408
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7138-4394 | True: 2744 | Pred: 2761
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8540+5844 | True: 14384 | Pred: 14355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2406+2409 | True: 4815 | Pred: 4744
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8499-4615 | True: 3884 | Pred: 3865
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 8036-1477 | True: 6559 | Pred: 6624
Epoch 48/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 61ms/step - accuracy: 0.5909 - loss: 1.0938 - val_accuracy: 0.5805 - val_loss: 1.1082
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1433-8392 | True: -6959 | Pred: -6969
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8617-9426 | True: -809 | Pred: -870
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 4002+2468 | True: 6470 | Pred: 6511
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3717-423 | True: 3294 | Pred: 3355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3523+8306 | True: 11829 | Pred: 11805
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 4968-1728 | True: 3240 | Pred: 3223
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5866-1405 | True: 4461 | Pred: 4415
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2703-3319 | True: -616 | Pred: -699
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 7727-2097 | True: 5630 | Pred: 5651
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 21ms/step
Q: 868-7141 | True: -6273 | Pred: -6335
Epoch 49/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">24s</span> 67ms/step - accuracy: 0.5964 - loss: 1.0797 - val_accuracy: 0.5752 - val_loss: 1.1142
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 795-5311 | True: -4516 | Pred: -4488
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3760+2280 | True: 6040 | Pred: 6955
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2330-8535 | True: -6205 | Pred: -6291
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 9642+1477 | True: 11119 | Pred: 11050
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 884-639 | True: 245 | Pred: 100
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3614+5154 | True: 8768 | Pred: 8713
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 3986+167 | True: 4153 | Pred: 4183
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2520-7078 | True: -4558 | Pred: -4521
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4862+4474 | True: 9336 | Pred: 9375
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8847-7131 | True: 1716 | Pred: 1795
Epoch 50/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 67ms/step - accuracy: 0.5940 - loss: 1.0852 - val_accuracy: 0.5810 - val_loss: 1.0995
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 5581+8449 | True: 14030 | Pred: 13022
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3986+167 | True: 4153 | Pred: 4186
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8295-5909 | True: 2386 | Pred: 2328
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 49ms/step
Q: 1348-9177 | True: -7829 | Pred: -7866
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 470+4627 | True: 5097 | Pred: 5111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 5034-5010 | True: 24 | Pred: 18
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 9634-8496 | True: 1138 | Pred: 1149
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 9330+3316 | True: 12646 | Pred: 12625
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 9748-1558 | True: 8190 | Pred: 8268
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 6016+9254 | True: 15270 | Pred: 15205
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="PyTorch"><strong>PyTorch</strong><a class="anchor-link" href="#PyTorch"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"embed_dim"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s2">"lr"</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">maxlen</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>  <span class="c1"># Input sequence length</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s2">"0123456789+- "</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="c1"># Character Table</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"char_to_index"</span><span class="p">:</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
    <span class="s2">"index_to_char"</span><span class="p">:</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
<span class="p">}</span>

<span class="c1"># Data Encoding</span>
<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">seq</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"index_to_char"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>

<span class="c1"># Generate Data</span>
<span class="n">questions</span><span class="p">,</span> <span class="n">answers</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">params</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">"+"</span><span class="p">,</span> <span class="s2">"-"</span><span class="p">])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">operation</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">eval</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">answers</span><span class="p">)):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train/Test Split</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Convert to PyTorch tensors</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Model Definition</span>
<span class="k">class</span> <span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_len</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Encoding</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="c1"># Decoding</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">embedded</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedded</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">embedded</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">))</span>
            <span class="n">step_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_output</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">step_output</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Feedback prediction</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Instantiate the model</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">"embed_dim"</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Training Setup</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">])</span>

<span class="c1"># Training Loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]):</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># Validation</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">val_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">val_outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">y_val</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Accuracy Calculation</span>
        <span class="n">val_preds</span> <span class="o">=</span> <span class="n">val_outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">val_targets</span> <span class="o">=</span> <span class="n">y_val</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">pred_seq</span><span class="p">,</span> <span class="n">target_seq</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">val_preds</span><span class="p">,</span> <span class="n">val_targets</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">pred_char</span><span class="p">,</span> <span class="n">target_char</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">pred_char</span> <span class="o">==</span> <span class="n">target_char</span><span class="p">:</span>
                    <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">params</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
          <span class="sa">f</span><span class="s2">"Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Print examples</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">params</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">val_outputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | True: </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Pred: </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50, Loss: 0.0166, Val Loss: 2.0417, Accuracy: 0.2742
Q: 8897+1019 | True: 9916 | Pred: 1119
Q: 6672+3345 | True: 10017 | Pred: 1019
Q: 457-2491 | True: -2034 | Pred: -236
Q: 8594+9957 | True: 18551 | Pred: 11119
Q: 4640+7946 | True: 12586 | Pred: 1019
Epoch 2/50, Loss: 0.0149, Val Loss: 1.8173, Accuracy: 0.3248
Epoch 3/50, Loss: 0.0138, Val Loss: 1.7091, Accuracy: 0.3559
Epoch 4/50, Loss: 0.0131, Val Loss: 1.6548, Accuracy: 0.3706
Epoch 5/50, Loss: 0.0127, Val Loss: 1.6088, Accuracy: 0.3996
Epoch 6/50, Loss: 0.0125, Val Loss: 1.5770, Accuracy: 0.4116
Epoch 7/50, Loss: 0.0123, Val Loss: 1.5585, Accuracy: 0.4112
Epoch 8/50, Loss: 0.0121, Val Loss: 1.5317, Accuracy: 0.4226
Epoch 9/50, Loss: 0.0120, Val Loss: 1.5146, Accuracy: 0.4272
Epoch 10/50, Loss: 0.0119, Val Loss: 1.5010, Accuracy: 0.4301
Epoch 11/50, Loss: 0.0118, Val Loss: 1.4900, Accuracy: 0.4357
Q: 5916-3703 | True: 2213 | Pred: 2199
Q: 8615-8058 | True: 557 | Pred: 103
Q: 500+4359 | True: 4859 | Pred: 5199
Q: 5218+35 | True: 5253 | Pred: 199
Q: 4202-6013 | True: -1811 | Pred: -1529
Epoch 12/50, Loss: 0.0117, Val Loss: 1.4798, Accuracy: 0.4337
Epoch 13/50, Loss: 0.0116, Val Loss: 1.4728, Accuracy: 0.4362
Epoch 14/50, Loss: 0.0115, Val Loss: 1.4646, Accuracy: 0.4390
Epoch 15/50, Loss: 0.0114, Val Loss: 1.4536, Accuracy: 0.4443
Epoch 16/50, Loss: 0.0114, Val Loss: 1.4474, Accuracy: 0.4483
Epoch 17/50, Loss: 0.0113, Val Loss: 1.4398, Accuracy: 0.4504
Epoch 18/50, Loss: 0.0113, Val Loss: 1.4469, Accuracy: 0.4466
Epoch 19/50, Loss: 0.0112, Val Loss: 1.4281, Accuracy: 0.4539
Epoch 20/50, Loss: 0.0111, Val Loss: 1.4309, Accuracy: 0.4511
Epoch 21/50, Loss: 0.0110, Val Loss: 1.4126, Accuracy: 0.4583
Q: 7523-8175 | True: -652 | Pred: -546
Q: 7624-600 | True: 7024 | Pred: 7999
Q: 8524+3430 | True: 11954 | Pred: 12019
Q: 6377-6185 | True: 192 | Pred: 209
Q: 457-619 | True: -162 | Pred: -309
Epoch 22/50, Loss: 0.0110, Val Loss: 1.4605, Accuracy: 0.4438
Epoch 23/50, Loss: 0.0110, Val Loss: 1.3996, Accuracy: 0.4621
Epoch 24/50, Loss: 0.0109, Val Loss: 1.3926, Accuracy: 0.4640
Epoch 25/50, Loss: 0.0108, Val Loss: 1.3952, Accuracy: 0.4623
Epoch 26/50, Loss: 0.0108, Val Loss: 1.3783, Accuracy: 0.4686
Epoch 27/50, Loss: 0.0107, Val Loss: 1.4031, Accuracy: 0.4592
Epoch 28/50, Loss: 0.0107, Val Loss: 1.3785, Accuracy: 0.4669
Epoch 29/50, Loss: 0.0106, Val Loss: 1.3780, Accuracy: 0.4639
Epoch 30/50, Loss: 0.0105, Val Loss: 1.3516, Accuracy: 0.4776
Epoch 31/50, Loss: 0.0105, Val Loss: 1.3530, Accuracy: 0.4755
Q: 1858+1391 | True: 3249 | Pred: 3076
Q: 5432+7796 | True: 13228 | Pred: 13202
Q: 843-7112 | True: -6269 | Pred: -6199
Q: 8736-3331 | True: 5405 | Pred: 5199
Q: 7672-5444 | True: 2228 | Pred: 2399
Epoch 32/50, Loss: 0.0104, Val Loss: 1.3448, Accuracy: 0.4768
Epoch 33/50, Loss: 0.0103, Val Loss: 1.3237, Accuracy: 0.4924
Epoch 34/50, Loss: 0.0103, Val Loss: 1.3494, Accuracy: 0.4747
Epoch 35/50, Loss: 0.0103, Val Loss: 1.3428, Accuracy: 0.4754
Epoch 36/50, Loss: 0.0102, Val Loss: 1.3301, Accuracy: 0.4817
Epoch 37/50, Loss: 0.0102, Val Loss: 1.3187, Accuracy: 0.4883
Epoch 38/50, Loss: 0.0101, Val Loss: 1.2961, Accuracy: 0.4991
Epoch 39/50, Loss: 0.0100, Val Loss: 1.3212, Accuracy: 0.4824
Epoch 40/50, Loss: 0.0100, Val Loss: 1.2756, Accuracy: 0.5104
Epoch 41/50, Loss: 0.0100, Val Loss: 1.2956, Accuracy: 0.4924
Q: 9254+3170 | True: 12424 | Pred: 12591
Q: 7335-5010 | True: 2325 | Pred: 2339
Q: 4588-476 | True: 4112 | Pred: 4019
Q: 393+3386 | True: 3779 | Pred: 3601
Q: 1076-5965 | True: -4889 | Pred: -4911
Epoch 42/50, Loss: 0.0100, Val Loss: 1.3056, Accuracy: 0.4863
Epoch 43/50, Loss: 0.0099, Val Loss: 1.2858, Accuracy: 0.4952
Epoch 44/50, Loss: 0.0098, Val Loss: 1.2566, Accuracy: 0.5152
Epoch 45/50, Loss: 0.0098, Val Loss: 1.2683, Accuracy: 0.5063
Epoch 46/50, Loss: 0.0098, Val Loss: 1.2489, Accuracy: 0.5150
Epoch 47/50, Loss: 0.0097, Val Loss: 1.2483, Accuracy: 0.5161
Epoch 48/50, Loss: 0.0097, Val Loss: 1.2504, Accuracy: 0.5117
Epoch 49/50, Loss: 0.0097, Val Loss: 1.2407, Accuracy: 0.5196
Epoch 50/50, Loss: 0.0096, Val Loss: 1.2362, Accuracy: 0.5218
Q: 6406+84 | True: 6490 | Pred: 5999
Q: 4686-3354 | True: 1332 | Pred: 1309
Q: 4932+6976 | True: 11908 | Pred: 11811
Q: 7564-279 | True: 7285 | Pred: 7909
Q: 8352-7160 | True: 1192 | Pred: 1301
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Improved-Model"><strong>Improved Model</strong><a class="anchor-link" href="#Improved-Model"></a></h1><p>Larger hidden size, smaller input size, embedding before LSTM, sparse categorial crossentropy loss function and integer encoding.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">RepeatVector</span>

<span class="c1"># Updated Hyperparameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>  <span class="c1"># Increased hidden size</span>
    <span class="s2">"embedding_size"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>  <span class="c1"># Embedding dimension</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>

<span class="n">maxlen</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s2">"0123456789+- "</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"char_to_index"</span><span class="p">:</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
    <span class="s2">"index_to_char"</span><span class="p">:</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Integer encode the sequence."""</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Decode integer-encoded sequence."""</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"index_to_char"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">)</span>

<span class="c1"># Data Generation</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">params</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">"+"</span><span class="p">,</span> <span class="s2">"-"</span><span class="p">])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">operation</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>  <span class="c1"># Calculate the result</span>
    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>  <span class="c1"># Padded to maxlen</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Padded to output length</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">questions</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">])</span>

<span class="c1"># Train / Test Split</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Model Definition with Embedding and Two LSTMs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"embedding_size"</span><span class="p">],</span> <span class="n">input_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">))</span>  <span class="c1"># Embedding Layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">]))</span>  <span class="c1"># Single Encoder LSTM Layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">RepeatVector</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Repeat vector for Decoder</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>  <span class="c1"># Decoder LSTM</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)))</span>  <span class="c1"># Dense Output Layer</span>


<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>

<span class="c1"># Training</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">params</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

    <span class="c1"># Test predictions on random samples</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | True: </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Pred: </span><span class="si">{</span><span class="n">pred</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">60s</span> 153ms/step - accuracy: 0.2279 - loss: 2.2064 - val_accuracy: 0.2846 - val_loss: 1.9358
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 408ms/step
Q: 7006+9197 | True: 16203 | Pred: 12244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2242-504 | True: 1738 | Pred: -155
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4314+9353 | True: 13667 | Pred: 12244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2841+9821 | True: 12662 | Pred: 12244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3343-9269 | True: -5926 | Pred: -2455
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 6530+7665 | True: 14195 | Pred: 12244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4926-7275 | True: -2349 | Pred: -255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 7528-9394 | True: -1866 | Pred: -255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 8582+8792 | True: 17374 | Pred: 11144
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 3625+4905 | True: 8530 | Pred: 12244
Epoch 2/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 157ms/step - accuracy: 0.3144 - loss: 1.8455 - val_accuracy: 0.3624 - val_loss: 1.6971
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8115+5619 | True: 13734 | Pred: 13255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 22ms/step
Q: 2150-1417 | True: 733 | Pred: 120
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 173-8330 | True: -8157 | Pred: -7855
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 2353-4286 | True: -1933 | Pred: -155
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 4335+9044 | True: 13379 | Pred: 13055
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 310-4052 | True: -3742 | Pred: -3555
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8818-457 | True: 8361 | Pred: 6800
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5343+611 | True: 5954 | Pred: 6025
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5687+3592 | True: 9279 | Pred: 8000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 8867-1283 | True: 7584 | Pred: 6550
Epoch 3/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 153ms/step - accuracy: 0.3709 - loss: 1.6654 - val_accuracy: 0.3870 - val_loss: 1.6145
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5778-6526 | True: -748 | Pred: -113
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 7384+2411 | True: 9795 | Pred: 9011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 8958+1233 | True: 10191 | Pred: 9061
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 5229-1984 | True: 3245 | Pred: 2846
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 23ms/step
Q: 4373-6330 | True: -1957 | Pred: -2163
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2460-3722 | True: -1262 | Pred: -1133
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3920-554 | True: 3366 | Pred: 4736
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7437+2001 | True: 9438 | Pred: 9061
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 263-8303 | True: -8040 | Pred: -8666
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5817-9482 | True: -3665 | Pred: -3466
Epoch 4/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 154ms/step - accuracy: 0.3966 - loss: 1.5845 - val_accuracy: 0.4160 - val_loss: 1.5277
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 4257+6907 | True: 11164 | Pred: 11398
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 8116-1248 | True: 6868 | Pred: 6433
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 8024+1145 | True: 9169 | Pred: 9037
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 5452-8753 | True: -3301 | Pred: -3333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 7276-4953 | True: 2323 | Pred: 2836
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 8344-6062 | True: 2282 | Pred: 2836
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 48ms/step
Q: 7051-713 | True: 6338 | Pred: 6506
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 7055+516 | True: 7571 | Pred: 8099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 6179-955 | True: 5224 | Pred: 4432
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 2902-7251 | True: -4349 | Pred: -4233
Epoch 5/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 156ms/step - accuracy: 0.4186 - loss: 1.5237 - val_accuracy: 0.4320 - val_loss: 1.4896
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2765+1217 | True: 3982 | Pred: 4544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 522-446 | True: 76 | Pred: 11
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1811+7206 | True: 9017 | Pred: 8114
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7293+3303 | True: 10596 | Pred: 10696
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7071-6771 | True: 300 | Pred: 42
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 5975-3521 | True: 2454 | Pred: 2444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6577+8759 | True: 15336 | Pred: 15699
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4907-1651 | True: 3256 | Pred: 3544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 9786-2279 | True: 7507 | Pred: 7119
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6503-9469 | True: -2966 | Pred: -2554
Epoch 6/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 156ms/step - accuracy: 0.4284 - loss: 1.4975 - val_accuracy: 0.4262 - val_loss: 1.4892
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3280+8231 | True: 11511 | Pred: 11587
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9938+4427 | True: 14365 | Pred: 14188
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 4668-4123 | True: 545 | Pred: 406
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3990+3165 | True: 7155 | Pred: 7777
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 9086-1660 | True: 7426 | Pred: 6774
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 4424-7823 | True: -3399 | Pred: -3277
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 566-6377 | True: -5811 | Pred: -5177
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6954-8833 | True: -1879 | Pred: -1775
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7297-3155 | True: 4142 | Pred: 3853
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3288-7093 | True: -3805 | Pred: -3277
Epoch 7/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 153ms/step - accuracy: 0.4380 - loss: 1.4689 - val_accuracy: 0.4358 - val_loss: 1.4725
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3993-8446 | True: -4453 | Pred: -4444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 787-8316 | True: -7529 | Pred: -7864
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3506-3733 | True: -227 | Pred: -444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8876+777 | True: 9653 | Pred: 9554
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 214+2390 | True: 2604 | Pred: 2583
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3368+7540 | True: 10908 | Pred: 10821
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6953-6778 | True: 175 | Pred: 414
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1455-5617 | True: -4162 | Pred: -4844
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 95+9057 | True: 9152 | Pred: 8114
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3788+9012 | True: 12800 | Pred: 12444
Epoch 8/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 156ms/step - accuracy: 0.4423 - loss: 1.4544 - val_accuracy: 0.4424 - val_loss: 1.4461
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9281+7685 | True: 16966 | Pred: 17233
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3450+9523 | True: 12973 | Pred: 12466
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7064-4505 | True: 2559 | Pred: 2241
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 2229+8028 | True: 10257 | Pred: 9001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2422-4536 | True: -2114 | Pred: -2207
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 4217-5419 | True: -1202 | Pred: -1396
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8747-3964 | True: 4783 | Pred: 4231
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8078-7215 | True: 863 | Pred: 103
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6242+1403 | True: 7645 | Pred: 7884
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8115+5619 | True: 13734 | Pred: 13966
Epoch 9/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 154ms/step - accuracy: 0.4502 - loss: 1.4392 - val_accuracy: 0.4462 - val_loss: 1.4407
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8903+3976 | True: 12879 | Pred: 12333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 1354-4985 | True: -3631 | Pred: -3000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 638-166 | True: 472 | Pred: 401
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5663-571 | True: 5092 | Pred: 5444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 4937+1928 | True: 6865 | Pred: 6333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5847-1144 | True: 4703 | Pred: 4433
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 5059+3100 | True: 8159 | Pred: 7533
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 2089+9347 | True: 11436 | Pred: 11383
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6947+6664 | True: 13611 | Pred: 13183
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3743-116 | True: 3627 | Pred: 3513
Epoch 10/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.4564 - loss: 1.4184 - val_accuracy: 0.4552 - val_loss: 1.4173
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 503+7825 | True: 8328 | Pred: 8031
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 272+9455 | True: 9727 | Pred: 9731
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 382+4687 | True: 5069 | Pred: 4339
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 4093-685 | True: 3408 | Pred: 3433
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 7408-9096 | True: -1688 | Pred: -1819
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 8224-7353 | True: 871 | Pred: 111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1175+2678 | True: 3853 | Pred: 4339
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4331+8193 | True: 12524 | Pred: 12333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 6537-4186 | True: 2351 | Pred: 2341
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3162-7086 | True: -3924 | Pred: -4999
Epoch 11/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 155ms/step - accuracy: 0.4659 - loss: 1.4004 - val_accuracy: 0.4587 - val_loss: 1.4092
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5264-5662 | True: -398 | Pred: -454
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8977+6771 | True: 15748 | Pred: 15444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7236+6655 | True: 13891 | Pred: 13444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 728-6486 | True: -5758 | Pred: -5244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 2299+9921 | True: 12220 | Pred: 12204
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9455-6798 | True: 2657 | Pred: 2942
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9992-5595 | True: 4397 | Pred: 4207
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9231-3758 | True: 5473 | Pred: 5707
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 2309-8486 | True: -6177 | Pred: -6254
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2535+3980 | True: 6515 | Pred: 6742
Epoch 12/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 155ms/step - accuracy: 0.4673 - loss: 1.3926 - val_accuracy: 0.4576 - val_loss: 1.4015
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5622-4023 | True: 1599 | Pred: 1718
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3668+991 | True: 4659 | Pred: 4400
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8644+6321 | True: 14965 | Pred: 14221
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7284-6401 | True: 883 | Pred: 903
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 5963+7882 | True: 13845 | Pred: 13151
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7760+7247 | True: 15007 | Pred: 14221
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4202-8748 | True: -4546 | Pred: -4355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8272+4068 | True: 12340 | Pred: 12221
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6447-7657 | True: -1210 | Pred: -1177
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 5066-1980 | True: 3086 | Pred: 3158
Epoch 13/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 155ms/step - accuracy: 0.4700 - loss: 1.3848 - val_accuracy: 0.4771 - val_loss: 1.3635
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8464+861 | True: 9325 | Pred: 9567
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1577-5798 | True: -4221 | Pred: -4399
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9068-4000 | True: 5068 | Pred: 4733
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 24ms/step
Q: 9101-257 | True: 8844 | Pred: 8699
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 8956+4383 | True: 13339 | Pred: 13999
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 8981+9134 | True: 18115 | Pred: 18299
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5816-9898 | True: -4082 | Pred: -4066
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4879+5920 | True: 10799 | Pred: 10759
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6910+2757 | True: 9667 | Pred: 9571
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1288-7693 | True: -6405 | Pred: -6999
Epoch 14/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 157ms/step - accuracy: 0.4788 - loss: 1.3667 - val_accuracy: 0.4749 - val_loss: 1.3661
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8599+6314 | True: 14913 | Pred: 14922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8706+9091 | True: 17797 | Pred: 18288
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8565+8599 | True: 17164 | Pred: 17277
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 4138+3838 | True: 7976 | Pred: 7032
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2150-1417 | True: 733 | Pred: 706
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 7605-7460 | True: 145 | Pred: 22
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 4779+2294 | True: 7073 | Pred: 7132
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 48ms/step
Q: 5206-4458 | True: 748 | Pred: 706
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 6516+8605 | True: 15121 | Pred: 15922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 3761-123 | True: 3638 | Pred: 3502
Epoch 15/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 154ms/step - accuracy: 0.4821 - loss: 1.3560 - val_accuracy: 0.4818 - val_loss: 1.3457
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6791-7997 | True: -1206 | Pred: -1288
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2897-4248 | True: -1351 | Pred: -1512
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2701-984 | True: 1717 | Pred: 2172
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7283-1004 | True: 6279 | Pred: 6463
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5063-3637 | True: 1426 | Pred: 1412
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 2767+9637 | True: 12404 | Pred: 12311
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 634-5337 | True: -4703 | Pred: -4359
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6889-7420 | True: -531 | Pred: -559
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7722+3835 | True: 11557 | Pred: 11621
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1880-2682 | True: -802 | Pred: -750
Epoch 16/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 154ms/step - accuracy: 0.4872 - loss: 1.3396 - val_accuracy: 0.4682 - val_loss: 1.3715
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 5787+6291 | True: 12078 | Pred: 11833
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 1013-4084 | True: -3071 | Pred: -3133
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 3178-5051 | True: -1873 | Pred: -1903
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 7380+2369 | True: 9749 | Pred: 9771
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 6285+1131 | True: 7416 | Pred: 7537
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4037+9864 | True: 13901 | Pred: 13883
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6942-4887 | True: 2055 | Pred: 2044
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4734+6426 | True: 11160 | Pred: 11033
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9948+6227 | True: 16175 | Pred: 16333
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5291+2497 | True: 7788 | Pred: 7833
Epoch 17/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.4860 - loss: 1.3415 - val_accuracy: 0.4893 - val_loss: 1.3218
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3747+2091 | True: 5838 | Pred: 5826
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2755+822 | True: 3577 | Pred: 3429
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7704-4878 | True: 2826 | Pred: 2742
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3979+2278 | True: 6257 | Pred: 6244
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5058-2601 | True: 2457 | Pred: 2488
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7711+1049 | True: 8760 | Pred: 8864
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2981-1385 | True: 1596 | Pred: 1484
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4043+4810 | True: 8853 | Pred: 8824
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4659+4164 | True: 8823 | Pred: 8824
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 136+5254 | True: 5390 | Pred: 5333
Epoch 18/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.4943 - loss: 1.3215 - val_accuracy: 0.4723 - val_loss: 1.3497
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3790-7883 | True: -4093 | Pred: -4055
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7486+5015 | True: 12501 | Pred: 12415
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7254+9907 | True: 17161 | Pred: 17118
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3477-1287 | True: 2190 | Pred: 2291
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8926-1846 | True: 7080 | Pred: 7481
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6800-4553 | True: 2247 | Pred: 2211
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2477+7448 | True: 9925 | Pred: 9881
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 8905-1630 | True: 7275 | Pred: 7481
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3792-9558 | True: -5766 | Pred: -5555
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 4991+9910 | True: 14901 | Pred: 14781
Epoch 19/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.4961 - loss: 1.3151 - val_accuracy: 0.4910 - val_loss: 1.3058
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1120-7822 | True: -6702 | Pred: -6855
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9537+5863 | True: 15400 | Pred: 15555
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 828+3914 | True: 4742 | Pred: 4038
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7646+3759 | True: 11405 | Pred: 11363
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3742-4800 | True: -1058 | Pred: -1122
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 9487-5359 | True: 4128 | Pred: 4113
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4556-2481 | True: 2075 | Pred: 2128
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6102-2797 | True: 3305 | Pred: 3388
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 1241-6173 | True: -4932 | Pred: -5000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7496+4846 | True: 12342 | Pred: 12206
Epoch 20/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.5065 - loss: 1.2882 - val_accuracy: 0.5033 - val_loss: 1.2849
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2416-8711 | True: -6295 | Pred: -6365
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6635+3255 | True: 9890 | Pred: 9903
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3144-7561 | True: -4417 | Pred: -4466
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 4772+6375 | True: 11147 | Pred: 11193
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5083-2165 | True: 2918 | Pred: 2988
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9869-6061 | True: 3808 | Pred: 3683
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7359+4430 | True: 11789 | Pred: 11796
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 602+6516 | True: 7118 | Pred: 7216
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 8864+6157 | True: 15021 | Pred: 15255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7242-1478 | True: 5764 | Pred: 5773
Epoch 21/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">57s</span> 162ms/step - accuracy: 0.5165 - loss: 1.2675 - val_accuracy: 0.5062 - val_loss: 1.2721
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 1013-4084 | True: -3071 | Pred: -2906
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 1822-3698 | True: -1876 | Pred: -1800
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 6922+4554 | True: 11476 | Pred: 11406
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 167-1451 | True: -1284 | Pred: -1380
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9560+9442 | True: 19002 | Pred: 18011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 43ms/step
Q: 9773-5597 | True: 4176 | Pred: 4211
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 8750-2825 | True: 5925 | Pred: 6000
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 7080-4655 | True: 2425 | Pred: 2468
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 2489+8014 | True: 10503 | Pred: 10376
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 49ms/step
Q: 9275+3186 | True: 12461 | Pred: 12466
Epoch 22/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 154ms/step - accuracy: 0.5198 - loss: 1.2536 - val_accuracy: 0.5030 - val_loss: 1.2722
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3722-4113 | True: -391 | Pred: -386
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1660+4571 | True: 6231 | Pred: 6254
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 804+6996 | True: 7800 | Pred: 7234
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8564+9875 | True: 18439 | Pred: 18586
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 728-6627 | True: -5899 | Pred: -5899
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 49ms/step
Q: 1193-7433 | True: -6240 | Pred: -6239
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 60ms/step
Q: 9539-6835 | True: 2704 | Pred: 2588
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 63ms/step
Q: 5129-5629 | True: -500 | Pred: -488
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 6101-2467 | True: 3634 | Pred: 3558
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 9882+9129 | True: 19011 | Pred: 18576
Epoch 23/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 155ms/step - accuracy: 0.5213 - loss: 1.2440 - val_accuracy: 0.5086 - val_loss: 1.2533
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8439-8296 | True: 143 | Pred: 11
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7359+4430 | True: 11789 | Pred: 11810
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 5150+8751 | True: 13901 | Pred: 13801
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2540+3872 | True: 6412 | Pred: 6268
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4098+3557 | True: 7655 | Pred: 7430
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 9973-8634 | True: 1339 | Pred: 1330
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6831-5617 | True: 1214 | Pred: 1230
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9853-8053 | True: 1800 | Pred: 1614
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9110-2425 | True: 6685 | Pred: 6530
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 1292-9126 | True: -7834 | Pred: -7927
Epoch 24/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 155ms/step - accuracy: 0.5213 - loss: 1.2375 - val_accuracy: 0.5062 - val_loss: 1.2653
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6474+2275 | True: 8749 | Pred: 8734
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 975+3435 | True: 4410 | Pred: 4288
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6312+4642 | True: 10954 | Pred: 10988
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6340+6939 | True: 13279 | Pred: 13088
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 27+6643 | True: 6670 | Pred: 6884
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 1526-5230 | True: -3704 | Pred: -3729
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 9848-4729 | True: 5119 | Pred: 5207
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3314+0 | True: 3314 | Pred: 3547
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6288+3046 | True: 9334 | Pred: 9228
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3178-5051 | True: -1873 | Pred: -1904
Epoch 25/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.5278 - loss: 1.2232 - val_accuracy: 0.5038 - val_loss: 1.2612
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9331-2738 | True: 6593 | Pred: 6649
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 2161-5883 | True: -3722 | Pred: -3622
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 800+9300 | True: 10100 | Pred: 1001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9205+9384 | True: 18589 | Pred: 18023
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 994+3420 | True: 4414 | Pred: 4446
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 2981-1385 | True: 1596 | Pred: 1664
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 7159+2207 | True: 9366 | Pred: 9368
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 9882-836 | True: 9046 | Pred: 9999
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7828-3870 | True: 3958 | Pred: 3914
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5348+9468 | True: 14816 | Pred: 14829
Epoch 26/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 156ms/step - accuracy: 0.5350 - loss: 1.2090 - val_accuracy: 0.5266 - val_loss: 1.2147
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3508-2634 | True: 874 | Pred: 900
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2589+8948 | True: 11537 | Pred: 11596
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9612+6689 | True: 16301 | Pred: 16346
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2579+423 | True: 3002 | Pred: 3816
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8845-8522 | True: 323 | Pred: 479
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 9700-2312 | True: 7388 | Pred: 7236
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 7737-1087 | True: 6650 | Pred: 6739
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7621-2698 | True: 4923 | Pred: 4913
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 8867-1283 | True: 7584 | Pred: 7786
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4215+5127 | True: 9342 | Pred: 9412
Epoch 27/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 157ms/step - accuracy: 0.5368 - loss: 1.2018 - val_accuracy: 0.5383 - val_loss: 1.1947
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5490+7815 | True: 13305 | Pred: 13331
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9259+6638 | True: 15897 | Pred: 15757
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8365+3293 | True: 11658 | Pred: 11611
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2376-3889 | True: -1513 | Pred: -1512
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9053+2057 | True: 11110 | Pred: 11071
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 9299-6024 | True: 3275 | Pred: 3277
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 2130-545 | True: 1585 | Pred: 1618
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 499-7126 | True: -6627 | Pred: -6673
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5398+1454 | True: 6852 | Pred: 6817
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 1199+9209 | True: 10408 | Pred: 10400
Epoch 28/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 157ms/step - accuracy: 0.5477 - loss: 1.1765 - val_accuracy: 0.5294 - val_loss: 1.2064
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6097+1933 | True: 8030 | Pred: 7929
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4365+1893 | True: 6258 | Pred: 6227
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 2350-4353 | True: -2003 | Pred: -2900
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9278+211 | True: 9489 | Pred: 9565
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 3993-8446 | True: -4453 | Pred: -4456
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 57-936 | True: -879 | Pred: -819
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 480+3823 | True: 4303 | Pred: 4329
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 8679-9083 | True: -404 | Pred: -499
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 9629+9477 | True: 19106 | Pred: 19221
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 686+92 | True: 778 | Pred: 621
Epoch 29/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.5461 - loss: 1.1758 - val_accuracy: 0.5395 - val_loss: 1.1795
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 2379-423 | True: 1956 | Pred: 2095
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 957+7713 | True: 8670 | Pred: 8860
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 7942-4525 | True: 3417 | Pred: 3450
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2341+9681 | True: 12022 | Pred: 12022
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3400-738 | True: 2662 | Pred: 2588
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9000+8097 | True: 17097 | Pred: 17455
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 5036+606 | True: 5642 | Pred: 5660
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9997+4892 | True: 14889 | Pred: 14788
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1727+212 | True: 1939 | Pred: 1984
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 1882-2272 | True: -390 | Pred: -480
Epoch 30/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.5532 - loss: 1.1598 - val_accuracy: 0.5348 - val_loss: 1.1942
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 167-1451 | True: -1284 | Pred: -1386
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8636+7273 | True: 15909 | Pred: 15858
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4844-7025 | True: -2181 | Pred: -2146
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 7690-3836 | True: 3854 | Pred: 3812
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4211+9983 | True: 14194 | Pred: 14101
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 5705-7909 | True: -2204 | Pred: -2108
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 1990+4886 | True: 6876 | Pred: 6888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 5356+7576 | True: 12932 | Pred: 12989
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7768-2448 | True: 5320 | Pred: 5384
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7149+4764 | True: 11913 | Pred: 11900
Epoch 31/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.5570 - loss: 1.1511 - val_accuracy: 0.5447 - val_loss: 1.1670
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8065-1007 | True: 7058 | Pred: 7967
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6858-5562 | True: 1296 | Pred: 1314
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5149+8571 | True: 13720 | Pred: 13604
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 9919-9519 | True: 400 | Pred: 400
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9938+3336 | True: 13274 | Pred: 13206
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 8365-3390 | True: 4975 | Pred: 5017
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 4381-3344 | True: 1037 | Pred: 103
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 5291-7330 | True: -2039 | Pred: -2004
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 98-7267 | True: -7169 | Pred: -7176
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4019+2512 | True: 6531 | Pred: 6662
Epoch 32/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.5620 - loss: 1.1420 - val_accuracy: 0.5260 - val_loss: 1.2120
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 2178-6787 | True: -4609 | Pred: -4544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7006+9197 | True: 16203 | Pred: 16310
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 161-8819 | True: -8658 | Pred: -8793
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 6888-3964 | True: 2924 | Pred: 3188
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 39ms/step
Q: 2270-8525 | True: -6255 | Pred: -6364
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 994+3420 | True: 4414 | Pred: 4444
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 687-8359 | True: -7672 | Pred: -7798
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5572+7489 | True: 13061 | Pred: 13099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6556-4858 | True: 1698 | Pred: 1718
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2965+1564 | True: 4529 | Pred: 4492
Epoch 33/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.5674 - loss: 1.1297 - val_accuracy: 0.5486 - val_loss: 1.1568
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8146-0 | True: 8146 | Pred: 8183
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3189+2303 | True: 5492 | Pred: 5512
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 498+8826 | True: 9324 | Pred: 9395
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8343-4004 | True: 4339 | Pred: 4255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7107-4864 | True: 2243 | Pred: 2222
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 579-7816 | True: -7237 | Pred: -7169
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 1431-2702 | True: -1271 | Pred: -1299
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9275+7297 | True: 16572 | Pred: 16588
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 2309-8486 | True: -6177 | Pred: -6161
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 7018+8134 | True: 15152 | Pred: 15153
Epoch 34/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 158ms/step - accuracy: 0.5701 - loss: 1.1210 - val_accuracy: 0.5515 - val_loss: 1.1565
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1436+1335 | True: 2771 | Pred: 2742
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 1877+53 | True: 1930 | Pred: 1974
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 3253-7921 | True: -4668 | Pred: -4666
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 1960+8657 | True: 10617 | Pred: 10546
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3056+7701 | True: 10757 | Pred: 10722
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 91+4904 | True: 4995 | Pred: 4064
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 8006-2857 | True: 5149 | Pred: 5111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 3312-3744 | True: -432 | Pred: -422
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 52ms/step
Q: 264+4697 | True: 4961 | Pred: 5011
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9844-2814 | True: 7030 | Pred: 6949
Epoch 35/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 160ms/step - accuracy: 0.5714 - loss: 1.1195 - val_accuracy: 0.5558 - val_loss: 1.1431
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7126+2403 | True: 9529 | Pred: 9515
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6494+1942 | True: 8436 | Pred: 8404
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4829+1686 | True: 6515 | Pred: 6544
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 1048+8634 | True: 9682 | Pred: 9715
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5356+7576 | True: 12932 | Pred: 12966
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7722+1167 | True: 8889 | Pred: 8966
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 5883+9036 | True: 14919 | Pred: 14949
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 56ms/step
Q: 8908-159 | True: 8749 | Pred: 8904
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 7236+6655 | True: 13891 | Pred: 13856
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 57ms/step
Q: 3265+3388 | True: 6653 | Pred: 6606
Epoch 36/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 157ms/step - accuracy: 0.5751 - loss: 1.1092 - val_accuracy: 0.5620 - val_loss: 1.1308
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 50ms/step
Q: 4967+4968 | True: 9935 | Pred: 9882
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 50ms/step
Q: 6858-5562 | True: 1296 | Pred: 1239
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 40ms/step
Q: 2148-9725 | True: -7577 | Pred: -7532
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 2919-7755 | True: -4836 | Pred: -4899
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 4640+6393 | True: 11033 | Pred: 11099
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 58ms/step
Q: 3144-7561 | True: -4417 | Pred: -4499
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 48ms/step
Q: 428-7602 | True: -7174 | Pred: -7199
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3895+1374 | True: 5269 | Pred: 5256
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 9369-8165 | True: 1204 | Pred: 1199
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 3249-2006 | True: 1243 | Pred: 1386
Epoch 37/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">54s</span> 155ms/step - accuracy: 0.5854 - loss: 1.0913 - val_accuracy: 0.5656 - val_loss: 1.1278
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 7005-7268 | True: -263 | Pred: -281
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 2172+324 | True: 2496 | Pred: 2414
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9179-7357 | True: 1822 | Pred: 1812
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 518-5154 | True: -4636 | Pred: -4699
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 51ms/step
Q: 2824-4093 | True: -1269 | Pred: -1133
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 5664-8428 | True: -2764 | Pred: -2816
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 9907-4774 | True: 5133 | Pred: 5219
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 9205+9384 | True: 18589 | Pred: 18681
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 53ms/step
Q: 4429+8795 | True: 13224 | Pred: 13243
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 207-1300 | True: -1093 | Pred: -1162
Epoch 38/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">55s</span> 155ms/step - accuracy: 0.5834 - loss: 1.0899 - val_accuracy: 0.5604 - val_loss: 1.1354
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 3613+3189 | True: 6802 | Pred: 6742
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 42ms/step
Q: 1813-613 | True: 1200 | Pred: 1279
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 5415+1675 | True: 7090 | Pred: 7094
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 386+5753 | True: 6139 | Pred: 6110
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 900-9256 | True: -8356 | Pred: -8496
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 56ms/step
Q: 9028+4168 | True: 13196 | Pred: 13206
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 9504-1245 | True: 8259 | Pred: 8117
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 45ms/step
Q: 7051-713 | True: 6338 | Pred: 6301
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 44ms/step
Q: 7995-769 | True: 7226 | Pred: 7180
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 54ms/step
Q: 9174+6003 | True: 15177 | Pred: 15250
Epoch 39/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.5853 - loss: 1.0910 - val_accuracy: 0.5594 - val_loss: 1.1351
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3643-5273 | True: -1630 | Pred: -1644
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9809+4812 | True: 14621 | Pred: 14537
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 6806-3563 | True: 3243 | Pred: 3248
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 8794-2824 | True: 5970 | Pred: 5944
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3722-4113 | True: -391 | Pred: -355
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2887-5453 | True: -2566 | Pred: -2534
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 979-9388 | True: -8409 | Pred: -8412
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3389+8443 | True: 11832 | Pred: 11888
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 1527-4675 | True: -3148 | Pred: -3131
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2935-3150 | True: -215 | Pred: -244
Epoch 40/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.5875 - loss: 1.0828 - val_accuracy: 0.5596 - val_loss: 1.1331
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 6079+7816 | True: 13895 | Pred: 13988
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 6998-5864 | True: 1134 | Pred: 1128
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5782-4837 | True: 945 | Pred: 876
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2481-2948 | True: -467 | Pred: -548
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7059-5222 | True: 1837 | Pred: 1868
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 9585-6480 | True: 3105 | Pred: 3078
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 8295+9685 | True: 17980 | Pred: 17936
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8963+3493 | True: 12456 | Pred: 12428
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 585-1733 | True: -1148 | Pred: -1182
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 4851-1254 | True: 3597 | Pred: 3588
Epoch 41/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 160ms/step - accuracy: 0.5912 - loss: 1.0735 - val_accuracy: 0.5702 - val_loss: 1.1141
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 428-7602 | True: -7174 | Pred: -7166
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8423-253 | True: 8170 | Pred: 8104
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8146+7818 | True: 15964 | Pred: 15055
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7793-1787 | True: 6006 | Pred: 6904
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 6873-3099 | True: 3774 | Pred: 3785
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 1446-2978 | True: -1532 | Pred: -1412
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3311+1107 | True: 4418 | Pred: 4421
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 41ms/step
Q: 9465-8642 | True: 823 | Pred: 876
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 6946+434 | True: 7380 | Pred: 7314
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6294-4181 | True: 2113 | Pred: 2068
Epoch 42/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">57s</span> 161ms/step - accuracy: 0.5971 - loss: 1.0610 - val_accuracy: 0.5576 - val_loss: 1.1400
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6491+3306 | True: 9797 | Pred: 9863
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4533-3667 | True: 866 | Pred: 876
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 4555-6611 | True: -2056 | Pred: -2014
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 9018+1612 | True: 10630 | Pred: 10522
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4753+8482 | True: 13235 | Pred: 13255
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2364-4829 | True: -2465 | Pred: -2491
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 1288-7693 | True: -6405 | Pred: -6362
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2627-5003 | True: -2376 | Pred: -2432
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 4180-5474 | True: -1294 | Pred: -1452
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3316+4875 | True: 8191 | Pred: 8252
Epoch 43/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.6026 - loss: 1.0531 - val_accuracy: 0.5706 - val_loss: 1.1075
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4364-5245 | True: -881 | Pred: -808
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5957+4647 | True: 10604 | Pred: 10520
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 7848+898 | True: 8746 | Pred: 8981
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4014+5976 | True: 9990 | Pred: 9901
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6808+1024 | True: 7832 | Pred: 7800
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 3392-8212 | True: -4820 | Pred: -4916
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 5105+3324 | True: 8429 | Pred: 8434
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3644+2353 | True: 5997 | Pred: 5977
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 2701-984 | True: 1717 | Pred: 1724
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 5318-5745 | True: -427 | Pred: -488
Epoch 44/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.6050 - loss: 1.0485 - val_accuracy: 0.5715 - val_loss: 1.1125
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 788+4315 | True: 5103 | Pred: 5173
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4768-7447 | True: -2679 | Pred: -2514
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 25ms/step
Q: 2983-1428 | True: 1555 | Pred: 1613
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1004-6709 | True: -5705 | Pred: -5840
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 8797+6610 | True: 15407 | Pred: 15457
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 9397+4716 | True: 14113 | Pred: 14111
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 7462-1763 | True: 5699 | Pred: 5733
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4668-4123 | True: 545 | Pred: 493
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2804+3186 | True: 5990 | Pred: 6917
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 2963+1151 | True: 4114 | Pred: 4003
Epoch 45/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.6115 - loss: 1.0333 - val_accuracy: 0.5775 - val_loss: 1.0971
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4161+3111 | True: 7272 | Pred: 7266
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 2653-5634 | True: -2981 | Pred: -2924
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 4216+2587 | True: 6803 | Pred: 6769
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 941+9250 | True: 10191 | Pred: 10266
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 6720-7478 | True: -758 | Pred: -746
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 2921+3087 | True: 6008 | Pred: 6977
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 5076+2004 | True: 7080 | Pred: 7126
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 2244-5626 | True: -3382 | Pred: -3344
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 8773-5919 | True: 2854 | Pred: 2812
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 6928+3561 | True: 10489 | Pred: 10408
Epoch 46/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.6125 - loss: 1.0305 - val_accuracy: 0.5806 - val_loss: 1.0955
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8729+9977 | True: 18706 | Pred: 18613
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8452+2382 | True: 10834 | Pred: 10822
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 1597-5842 | True: -4245 | Pred: -4299
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5274-9972 | True: -4698 | Pred: -4724
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 4145+2920 | True: 7065 | Pred: 7039
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 7594+3479 | True: 11073 | Pred: 11034
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 38ms/step
Q: 9874+9050 | True: 18924 | Pred: 19922
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5696+6161 | True: 11857 | Pred: 11889
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 9809+4812 | True: 14621 | Pred: 14619
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 3558+6921 | True: 10479 | Pred: 10428
Epoch 47/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">57s</span> 161ms/step - accuracy: 0.6171 - loss: 1.0212 - val_accuracy: 0.5780 - val_loss: 1.1044
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9780+4621 | True: 14401 | Pred: 14454
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5627-7567 | True: -1940 | Pred: -1914
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 3302+8495 | True: 11797 | Pred: 11872
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 8486+1223 | True: 9709 | Pred: 9771
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 9228-6618 | True: 2610 | Pred: 2592
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 3930-1121 | True: 2809 | Pred: 2720
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 9741+7597 | True: 17338 | Pred: 17320
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 9859+1609 | True: 11468 | Pred: 11477
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 7711-5852 | True: 1859 | Pred: 1824
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 1872+4806 | True: 6678 | Pred: 6742
Epoch 48/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">57s</span> 161ms/step - accuracy: 0.6148 - loss: 1.0231 - val_accuracy: 0.5821 - val_loss: 1.0944
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 9844-2814 | True: 7030 | Pred: 7935
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 1432+8864 | True: 10296 | Pred: 10268
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7438-1095 | True: 6343 | Pred: 6233
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 641+6102 | True: 6743 | Pred: 6743
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 3566+5153 | True: 8719 | Pred: 8733
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4554-9136 | True: -4582 | Pred: -4653
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 6207+3839 | True: 10046 | Pred: 10045
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 54ms/step
Q: 6000-377 | True: 5623 | Pred: 5611
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 8916+293 | True: 9209 | Pred: 9184
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 8047-6364 | True: 1683 | Pred: 1663
Epoch 49/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 159ms/step - accuracy: 0.6244 - loss: 1.0005 - val_accuracy: 0.5798 - val_loss: 1.0930
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 4798+5341 | True: 10139 | Pred: 10117
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8736+1151 | True: 9887 | Pred: 9831
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 8766+3325 | True: 12091 | Pred: 12017
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 5456+4784 | True: 10240 | Pred: 10226
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3571+1297 | True: 4868 | Pred: 4843
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9671-4227 | True: 5444 | Pred: 5214
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 6338+4095 | True: 10433 | Pred: 10463
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4031-6775 | True: -2744 | Pred: -2736
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3171-6352 | True: -3181 | Pred: -3251
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 5741-9928 | True: -4187 | Pred: -4295
Epoch 50/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">56s</span> 160ms/step - accuracy: 0.6299 - loss: 0.9878 - val_accuracy: 0.5841 - val_loss: 1.0928
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 670-5377 | True: -4707 | Pred: -4727
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 7730+2978 | True: 10708 | Pred: 10708
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 9786-2279 | True: 7507 | Pred: 7500
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 37ms/step
Q: 6261-6023 | True: 238 | Pred: 350
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 5547+7115 | True: 12662 | Pred: 12664
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 30ms/step
Q: 4377-424 | True: 3953 | Pred: 3956
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 32ms/step
Q: 3526+6949 | True: 10475 | Pred: 10404
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 9404+654 | True: 10058 | Pred: 10001
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 46ms/step
Q: 5720-9995 | True: -4275 | Pred: -4203
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 47ms/step
Q: 4730+871 | True: 5601 | Pred: 5504
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.2).</p>
<p>a) Do you think this model performs well?  Why or why not?<br/>
b) What are its limitations?<br/>
c) What would you do to improve it?<br/>
d) Can you apply an attention mechanism to this model? Why or why not?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="ANSWERS-FOR-1.2"><strong>ANSWERS FOR 1.2</strong><a class="anchor-link" href="#ANSWERS-FOR-1.2"></a></h1><h1 id="a)"><strong>a)</strong><a class="anchor-link" href="#a)"></a></h1><p>The model performs reasonably well but has noticeable shortcomings that affect its overall reliability.</p>
<p>Strengths:</p>
<ol>
<li>Ability to Learn Basic Patterns:</li>
</ol>
<p>The model can generate predictions that are often close to the correct outputs, indicating that it has learned some patterns of addition and subtraction.</p>
<p>Training loss consistently decreases, showing the model effectively minimizes errors on the training set.</p>
<ol start="2">
<li>Handling a Range of Inputs:</li>
</ol>
<p>The model performs adequately on randomly generated equations, showing it has generalized to a reasonable extent, especially for simpler cases.</p>
<p>Weaknesses:</p>
<ol>
<li>Validation Loss Fluctuations:</li>
</ol>
<p>The validation loss fluctuates significantly and does not decrease as consistently as the training loss. This indicates the model struggles to generalize well to unseen data, potentially due to overfitting.</p>
<ol start="2">
<li>Prediction Errors:</li>
</ol>
<p>The model makes some errors that deviate significantly from the correct answers.</p>
<p>These errors may result from error propagation during decoding, where incorrect predictions in earlier time steps negatively affect later steps.</p>
<ol start="3">
<li>Mismatch Between Training and Inference (Teacher Forcing):</li>
</ol>
<p>The model uses ground truth during training (teacher forcing) but relies on its own predictions during inference. This discrepancy can lead to cascading errors during testing.</p>
<ol start="4">
<li>Simplistic Design:</li>
</ol>
<p>The model lacks attention mechanisms or other strategies that might help it focus on relevant parts of the input sequence, limiting its ability to handle more complex or edge case inputs.</p>
<p>Overall Performance:</p>
<p>The model performs adequately for simple examples but struggles with generalization and robustness, particularly for more complex or edge case inputs. its limitations, such as fluctuating validation loss and occasional large prediction errors, indicate that improvements are needed for reliable performance across all cases.</p>
<p>In conclusion, the model performs moderately well but does not consistently achieve high accuracy, particularly on unseen data.</p>
<h1 id="b)"><strong>b)</strong><a class="anchor-link" href="#b)"></a></h1><ol>
<li>Error Propagation in Decoding Without Teacher Forcing:</li>
</ol>
<p>During inference, the model relies on its own predictions to generate the next input (instead of ground truth), leading to error accumulation. If an early prediction is incorrect, it can mislead subsequent predictions, especially for longer sequences.
This can result in cascading errors, particularly for more complex problems or larger numbers.</p>
<ol start="2">
<li>Lack of Rich Semantic Embedding:</li>
</ol>
<p>The embedding in the Keras implementation is implemented as a dense layer, which is less robust compared to learned embeddings like PyTorch's nn.Embedding. It treats input tokens as isolated entities and doesn't leverage relationships or patterns between them effectively.
This limits the models ability to capture deeper structural relationships.</p>
<ol start="3">
<li>Overfitting to Training Data:</li>
</ol>
<p>The model could memorize patterns in the training data, particularly when the training set is small or lacks diversity.
This would reduce its ability to generalize to unseen or edge case equations.</p>
<ol start="4">
<li>Lack of Attention Mechanism:</li>
</ol>
<p>The model lacks an attention mechanism, which could help it focus on specific parts of the input sequence during decoding.
Without attention, the model processes all input tokens uniformly, which may hinder its ability to learn complex, position specific dependencies effectively.</p>
<h1 id="c)"><strong>c)</strong><a class="anchor-link" href="#c)"></a></h1><ol>
<li>Use a Learned Embedding Layer:</li>
</ol>
<p>The current embedding is a dense layer, which is less effective at capturing semantic relationships between input tokens.
Replace the dense layer embedding with a proper learned embedding layer (for example PyTorchs nn.Embedding). This approach will
Learn a distributed representation of tokens during training and Better capture patterns and relationships between input tokens.</p>
<ol start="2">
<li>Incorporate Attention Mechanisms:</li>
</ol>
<p>The model processes the input uniformly and struggles with position specific dependencies.
The solution is to Add an attention mechanism to the decoder. This would allow the model to focus on relevant parts of the input sequence during each decoding step.
This would enhance the models ability to handle long term dependencies and improve accuracy on complex arithmetic tasks.</p>
<ol start="3">
<li>Use Pretraining or Transfer Learning:</li>
</ol>
<p>The model is trained from scratch, which can be slow and suboptimal for learning general patterns.
Solution: Pretrain the encoder or decoder on related tasks (for example language modeling or sequence prediction) and fine tune for arithmetic tasks.
Pretraining provides the model with a strong initialization, leading to faster convergence and improved performance.</p>
<h1 id="d)"><strong>d)</strong><a class="anchor-link" href="#d)"></a></h1><p>Yes, attention can be integrated into this model because:</p>
<ol>
<li><p>Encoder-Decoder Architecture: Attention mechanisms are designed to work with encoder-decoder setups like the one in this model.</p>
</li>
<li><p>Compatibility: Attention does not fundamentally alter the structure but enhances it by modifying how the decoder accesses the encoders output.</p>
</li>
<li><p>Task Relevance: For sequence to sequence tasks like arithmetic equation solving, attention can help the model identify relevant parts of the input sequence for generating each output token.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.3).</p>
<p>Add attention to the model. Evaluate the performance against the <code>seq2seq</code> you trained above. Which one is performing better?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answers-for-1.3)"><strong>Answers for 1.3)</strong><a class="anchor-link" href="#Answers-for-1.3)"></a></h1><p>Performance:</p>
<p>Accuracy: The model with attention achieves 56.5% training accuracy and 54.9% validation accuracy by the final epoch. While slightly lower than the basic models best accuracy, the attention model performs better in handling long sequences and edge cases.</p>
<p>mproved Predictions:
Predictions are closer to the true values compared to the vanilla model, especially for longer or more complex sequences.
For examples:</p>
<p>Q: 7851+2214 | True: 10065 | Pred: 10002  Small error compared to larger deviations in the vanilla model.</p>
<p>Q: 3910+4285 | True: 8195 | Pred: 8177  More accurate than without attention.</p>
<p>Benefits of Attention:</p>
<p>Dynamic Context: The attention mechanism overcomes the bottleneck of a fixed length context vector by dynamically attending to relevant parts of the input sequence.</p>
<p>Improved Long Sequence Handling: Predictions for longer sequences are more accurate and consistent.</p>
<p>Error Reduction: The attention mechanism reduces large errors, particularly for sequences requiring precise arithmetic operations.</p>
<p>The results show that while both models achieve similar overall accuracy, the attention mechanism provides a significant qualitative improvement in handling complex and longer sequences.</p>
<p>Qualitative Performance:</p>
<p>Error Handling:</p>
<p>Without Attention:
The predictions often deviate significantly for longer or complex sequences. Inaccurate for subtraction.</p>
<p>With Attention:</p>
<p>Errors are smaller and more localized.</p>
<p>Handling of Long Sequences:</p>
<p>The model with attention handles long sequences and complex operations better by focusing dynamically on relevant parts of the input.</p>
<p>The fixed length context vector of the model without attention causes performance degradation for such cases.</p>
<p>The attention mechanism provides a better ability to generalize to unseen or complex inputs. While its overall accuracy is slightly lower, it shows better alignment between input and output patterns, especially for tasks requiring more nuanced understanding.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Code-with-Attention-Mechanism"><strong>Code with Attention Mechanism</strong><a class="anchor-link" href="#Code-with-Attention-Mechanism"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">RepeatVector</span><span class="p">,</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Concatenate</span>

<span class="c1"># Parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>

<span class="n">maxlen</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s2">"0123456789+- "</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="c1"># Character Table</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"char_to_index"</span><span class="p">:</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
    <span class="s2">"index_to_char"</span><span class="p">:</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
<span class="p">}</span>

<span class="c1"># Encoding/Decoding Functions</span>
<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">seq</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"index_to_char"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>

<span class="c1"># Generate Data</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">params</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">"+"</span><span class="p">,</span> <span class="s2">"-"</span><span class="p">])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">operation</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">),</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">questions</span><span class="p">,</span> <span class="n">answers</span><span class="p">)):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">answer</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

<span class="c1"># Train / Test Split</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Prepare Decoder Inputs</span>
<span class="n">decoder_inputs_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">decoder_inputs_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">decoder_inputs_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="s2">" "</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">decoder_inputs_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
<span class="n">decoder_inputs_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">decoder_inputs_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="s2">" "</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Model Definition with Attention</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
<span class="n">encoder_lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder_lstm</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">encoder_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
<span class="n">decoder_lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder_lstm</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_states</span><span class="p">)</span>

<span class="n">attention_dot</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])([</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>
<span class="n">attention_softmax</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">'softmax'</span><span class="p">)(</span><span class="n">attention_dot</span><span class="p">)</span>
<span class="n">context_vector</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])([</span><span class="n">attention_softmax</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>
<span class="n">decoder_combined_context</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)([</span><span class="n">context_vector</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="p">])</span>

<span class="n">output_dense</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">))</span>
<span class="n">decoder_predictions</span> <span class="o">=</span> <span class="n">output_dense</span><span class="p">(</span><span class="n">decoder_combined_context</span><span class="p">)</span>

<span class="n">attention_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span> <span class="n">decoder_predictions</span><span class="p">)</span>
<span class="n">attention_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>

<span class="c1"># Training</span>
<span class="n">attention_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="p">[</span><span class="n">x_train</span><span class="p">,</span> <span class="n">decoder_inputs_train</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">x_val</span><span class="p">,</span> <span class="n">decoder_inputs_val</span><span class="p">],</span> <span class="n">y_val</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Evaluate Model</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">attention_model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">decoder_inputs_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]])[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | True: </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Pred: </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">28s</span> 62ms/step - accuracy: 0.2492 - loss: 2.1565 - val_accuracy: 0.2936 - val_loss: 1.9130
Epoch 2/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 60ms/step - accuracy: 0.2948 - loss: 1.8914 - val_accuracy: 0.3076 - val_loss: 1.8328
Epoch 3/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 63ms/step - accuracy: 0.3136 - loss: 1.8134 - val_accuracy: 0.3415 - val_loss: 1.7428
Epoch 4/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 61ms/step - accuracy: 0.3448 - loss: 1.7202 - val_accuracy: 0.3568 - val_loss: 1.6798
Epoch 5/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.3671 - loss: 1.6578 - val_accuracy: 0.3808 - val_loss: 1.6195
Epoch 6/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 59ms/step - accuracy: 0.3886 - loss: 1.6119 - val_accuracy: 0.3900 - val_loss: 1.5922
Epoch 7/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 58ms/step - accuracy: 0.3987 - loss: 1.5817 - val_accuracy: 0.4042 - val_loss: 1.5616
Epoch 8/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.4107 - loss: 1.5523 - val_accuracy: 0.4120 - val_loss: 1.5421
Epoch 9/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 62ms/step - accuracy: 0.4187 - loss: 1.5317 - val_accuracy: 0.4296 - val_loss: 1.5084
Epoch 10/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 61ms/step - accuracy: 0.4289 - loss: 1.5093 - val_accuracy: 0.4391 - val_loss: 1.4880
Epoch 11/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 62ms/step - accuracy: 0.4371 - loss: 1.4869 - val_accuracy: 0.4266 - val_loss: 1.5022
Epoch 12/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 59ms/step - accuracy: 0.4443 - loss: 1.4679 - val_accuracy: 0.4500 - val_loss: 1.4465
Epoch 13/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 59ms/step - accuracy: 0.4521 - loss: 1.4421 - val_accuracy: 0.4611 - val_loss: 1.4194
Epoch 14/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 61ms/step - accuracy: 0.4601 - loss: 1.4152 - val_accuracy: 0.4636 - val_loss: 1.4000
Epoch 15/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 62ms/step - accuracy: 0.4693 - loss: 1.3903 - val_accuracy: 0.4582 - val_loss: 1.3946
Epoch 16/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 60ms/step - accuracy: 0.4735 - loss: 1.3722 - val_accuracy: 0.4734 - val_loss: 1.3600
Epoch 17/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">19s</span> 55ms/step - accuracy: 0.4792 - loss: 1.3579 - val_accuracy: 0.4853 - val_loss: 1.3308
Epoch 18/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 61ms/step - accuracy: 0.4857 - loss: 1.3379 - val_accuracy: 0.4912 - val_loss: 1.3213
Epoch 19/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.4930 - loss: 1.3206 - val_accuracy: 0.4960 - val_loss: 1.3018
Epoch 20/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 60ms/step - accuracy: 0.4986 - loss: 1.3041 - val_accuracy: 0.4871 - val_loss: 1.3104
Epoch 21/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.4961 - loss: 1.3056 - val_accuracy: 0.5086 - val_loss: 1.2795
Epoch 22/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 60ms/step - accuracy: 0.5058 - loss: 1.2818 - val_accuracy: 0.5040 - val_loss: 1.2836
Epoch 23/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">19s</span> 55ms/step - accuracy: 0.5059 - loss: 1.2775 - val_accuracy: 0.5061 - val_loss: 1.2695
Epoch 24/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 60ms/step - accuracy: 0.5103 - loss: 1.2681 - val_accuracy: 0.5229 - val_loss: 1.2496
Epoch 25/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">19s</span> 54ms/step - accuracy: 0.5162 - loss: 1.2549 - val_accuracy: 0.5089 - val_loss: 1.2573
Epoch 26/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 59ms/step - accuracy: 0.5205 - loss: 1.2445 - val_accuracy: 0.5168 - val_loss: 1.2447
Epoch 27/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 60ms/step - accuracy: 0.5203 - loss: 1.2398 - val_accuracy: 0.5250 - val_loss: 1.2329
Epoch 28/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 60ms/step - accuracy: 0.5198 - loss: 1.2406 - val_accuracy: 0.5213 - val_loss: 1.2294
Epoch 29/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 58ms/step - accuracy: 0.5286 - loss: 1.2275 - val_accuracy: 0.5204 - val_loss: 1.2383
Epoch 30/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.5240 - loss: 1.2339 - val_accuracy: 0.5411 - val_loss: 1.2060
Epoch 31/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 58ms/step - accuracy: 0.5356 - loss: 1.2113 - val_accuracy: 0.5418 - val_loss: 1.2054
Epoch 32/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 58ms/step - accuracy: 0.5345 - loss: 1.2111 - val_accuracy: 0.5196 - val_loss: 1.2260
Epoch 33/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.5352 - loss: 1.2082 - val_accuracy: 0.5120 - val_loss: 1.2420
Epoch 34/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 56ms/step - accuracy: 0.5351 - loss: 1.2040 - val_accuracy: 0.5221 - val_loss: 1.2172
Epoch 35/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 61ms/step - accuracy: 0.5354 - loss: 1.2047 - val_accuracy: 0.5292 - val_loss: 1.2014
Epoch 36/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 61ms/step - accuracy: 0.5452 - loss: 1.1863 - val_accuracy: 0.5559 - val_loss: 1.1775
Epoch 37/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 60ms/step - accuracy: 0.5468 - loss: 1.1829 - val_accuracy: 0.5398 - val_loss: 1.1925
Epoch 38/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 59ms/step - accuracy: 0.5471 - loss: 1.1800 - val_accuracy: 0.5466 - val_loss: 1.1784
Epoch 39/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">40s</span> 56ms/step - accuracy: 0.5456 - loss: 1.1811 - val_accuracy: 0.5452 - val_loss: 1.1765
Epoch 40/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 61ms/step - accuracy: 0.5522 - loss: 1.1696 - val_accuracy: 0.5247 - val_loss: 1.2004
Epoch 41/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 63ms/step - accuracy: 0.5480 - loss: 1.1784 - val_accuracy: 0.5358 - val_loss: 1.1841
Epoch 42/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 62ms/step - accuracy: 0.5486 - loss: 1.1743 - val_accuracy: 0.5238 - val_loss: 1.2042
Epoch 43/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 62ms/step - accuracy: 0.5471 - loss: 1.1752 - val_accuracy: 0.5463 - val_loss: 1.1764
Epoch 44/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.5536 - loss: 1.1623 - val_accuracy: 0.5391 - val_loss: 1.1715
Epoch 45/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">23s</span> 63ms/step - accuracy: 0.5588 - loss: 1.1552 - val_accuracy: 0.5692 - val_loss: 1.1490
Epoch 46/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">39s</span> 58ms/step - accuracy: 0.5620 - loss: 1.1494 - val_accuracy: 0.5152 - val_loss: 1.2548
Epoch 47/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">21s</span> 59ms/step - accuracy: 0.5493 - loss: 1.1697 - val_accuracy: 0.5370 - val_loss: 1.1850
Epoch 48/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 60ms/step - accuracy: 0.5629 - loss: 1.1445 - val_accuracy: 0.5510 - val_loss: 1.1571
Epoch 49/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">20s</span> 56ms/step - accuracy: 0.5573 - loss: 1.1530 - val_accuracy: 0.5694 - val_loss: 1.1399
Epoch 50/50
<span class="ansi-bold">352/352</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">22s</span> 61ms/step - accuracy: 0.5650 - loss: 1.1394 - val_accuracy: 0.5492 - val_loss: 1.1545
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 470ms/step
Q: 7851+2214 | True: 10065 | Pred: 10002
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7391+5529 | True: 12920 | Pred: 12802
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 26ms/step
Q: 3198-3256 | True: -58 | Pred: -1
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 27ms/step
Q: 4675-2037 | True: 2638 | Pred: 2605
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 5059+557 | True: 5616 | Pred: 5603
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 4944-6100 | True: -1156 | Pred: -1299
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 3910+4285 | True: 8195 | Pred: 8177
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 28ms/step
Q: 8376-3661 | True: 4715 | Pred: 4750
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 31ms/step
Q: 7936-6410 | True: 1526 | Pred: 1407
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 29ms/step
Q: 446-9843 | True: -9397 | Pred: -9356
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.4)</p>
<p>Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-1.4)"><strong>Answer 1.4)</strong><a class="anchor-link" href="#Answer-1.4)"></a></h1><p>Enhanced Gradient Flow and Input Preservation:</p>
<p>Residual connections help retain input features and improve gradient flow, especially in deeper architectures. This leads to more stable training and better convergence.</p>
<p>Stable Learning Dynamics:</p>
<p>Layer normalization ensures consistent and stable updates during training, reducing variance in gradient updates.</p>
<p>Improved Attention Mechanism:</p>
<p>Scaled dot product attention improves numerical stability and allows the model to better focus on relevant parts of the sequence, particularly beneficial for long term dependencies.</p>
<p>Better Generalization:</p>
<p>The learning rate scheduler dynamically adjusts the learning rate, leading to better generalization on validation data as training progresses.</p>
<p>Efficient Encoding:</p>
<p>The integer encoding combined with embedding and projection layers reduces memory usage and computation overhead compared to one hot encoding.</p>
<p>The code in 1.4 integrates advanced techniques (residual connections, normalization, scaled attention, and learning rate scheduling) that improve the models ability to learn complex patterns, focus on important parts of the input sequence, and generalize better. These additions come at the cost of longer training times but lead to better overall accuracy and robustness in predictions.</p>
<p>It is better in accuracy and generalization, especially for larger or more complex datasets. While it may not be as fast as simpler models, its better suited for tasks requiring high precision and stability.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">40000</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s1">'0123456789-+ '</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Concatenate</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">LayerNormalization</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">LearningRateScheduler</span>


<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"training_size"</span><span class="p">:</span> <span class="mi">40000</span><span class="p">,</span>
    <span class="s2">"digits"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">"hidden_size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="s2">"embedding_size"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">0.001</span>
<span class="p">}</span>

<span class="n">maxlen</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s2">"0123456789+- "</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="c1"># Character Table</span>
<span class="n">ctable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"char_to_index"</span><span class="p">:</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
    <span class="s2">"index_to_char"</span><span class="p">:</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)},</span>
<span class="p">}</span>

<span class="c1"># Encoding/Decoding Functions</span>
<span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Integer encode the sequence."""</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Decode integer-encoded sequence."""</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ctable</span><span class="p">[</span><span class="s2">"index_to_char"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">)</span>

<span class="c1"># Generate Data</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">operation</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">"+"</span><span class="p">,</span> <span class="s2">"-"</span><span class="p">])</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">operation</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">maxlen</span><span class="p">))</span>
    <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">questions</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">])</span>

<span class="c1"># Train / Test Split</span>
<span class="n">split_at</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_at</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_at</span><span class="p">:]</span>

<span class="c1"># Prepare Decoder Inputs</span>
<span class="n">decoder_inputs_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">decoder_inputs_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">decoder_inputs_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="s2">" "</span><span class="p">]</span>

<span class="n">decoder_inputs_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
<span class="n">decoder_inputs_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">decoder_inputs_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctable</span><span class="p">[</span><span class="s2">"char_to_index"</span><span class="p">][</span><span class="s2">" "</span><span class="p">]</span>

<span class="c1"># Model Definition</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,))</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"embedding_size"</span><span class="p">])(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">embedded_norm</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">()(</span><span class="n">embedding</span><span class="p">)</span>

<span class="c1"># Project embedding to match hidden size</span>
<span class="n">projected_embedding</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">])(</span><span class="n">embedded_norm</span><span class="p">)</span>

<span class="c1"># Encoder</span>
<span class="n">encoder_gru</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span> <span class="o">=</span> <span class="n">encoder_gru</span><span class="p">(</span><span class="n">projected_embedding</span><span class="p">)</span>

<span class="c1"># Residual Connection</span>
<span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">projected_embedding</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>

<span class="c1"># Decoder</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,))</span>
<span class="n">decoder_embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"embedding_size"</span><span class="p">])(</span><span class="n">decoder_inputs</span><span class="p">)</span>
<span class="n">decoder_gru</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder_gru</span><span class="p">(</span><span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">state_h</span><span class="p">)</span>

<span class="c1"># Scaled Dot Product Attention</span>
<span class="n">attention_scores</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])([</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"attention_scale"</span><span class="p">)</span>
<span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">*</span> <span class="n">scale</span>
<span class="n">attention_softmax</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">'softmax'</span><span class="p">)(</span><span class="n">attention_scores</span><span class="p">)</span>
<span class="n">context_vector</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])([</span><span class="n">attention_softmax</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>
<span class="n">decoder_combined_context</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)([</span><span class="n">context_vector</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="p">])</span>

<span class="c1"># Output Layer</span>
<span class="n">output_dense</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">))</span>
<span class="n">decoder_predictions</span> <span class="o">=</span> <span class="n">output_dense</span><span class="p">(</span><span class="n">decoder_combined_context</span><span class="p">)</span>

<span class="c1"># Compile Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span> <span class="n">decoder_predictions</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>

<span class="c1"># Learning Rate Scheduler</span>
<span class="k">def</span> <span class="nf">scheduler</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">lr</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">lr</span>

<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># Training</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="p">[</span><span class="n">x_train</span><span class="p">,</span> <span class="n">decoder_inputs_train</span><span class="p">],</span>
    <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">],</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">x_val</span><span class="p">,</span> <span class="n">decoder_inputs_val</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">lr_scheduler</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Evaluate Model</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">decode</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">x_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">decoder_inputs_val</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | True: </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2"> | Pred: </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">50s</span> 150ms/step - accuracy: 0.2622 - loss: 2.0756 - val_accuracy: 0.3479 - val_loss: 1.7206 - learning_rate: 0.0010
Epoch 2/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.3646 - loss: 1.6795 - val_accuracy: 0.4099 - val_loss: 1.5623 - learning_rate: 0.0010
Epoch 3/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.4091 - loss: 1.5541 - val_accuracy: 0.4293 - val_loss: 1.5001 - learning_rate: 0.0010
Epoch 4/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 145ms/step - accuracy: 0.4285 - loss: 1.4960 - val_accuracy: 0.4389 - val_loss: 1.4618 - learning_rate: 0.0010
Epoch 5/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.4435 - loss: 1.4532 - val_accuracy: 0.4515 - val_loss: 1.4208 - learning_rate: 0.0010
Epoch 6/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.4574 - loss: 1.4135 - val_accuracy: 0.4711 - val_loss: 1.3740 - learning_rate: 0.0010
Epoch 7/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.4727 - loss: 1.3686 - val_accuracy: 0.4809 - val_loss: 1.3366 - learning_rate: 0.0010
Epoch 8/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.4841 - loss: 1.3312 - val_accuracy: 0.4938 - val_loss: 1.3034 - learning_rate: 0.0010
Epoch 9/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 145ms/step - accuracy: 0.5005 - loss: 1.2933 - val_accuracy: 0.5053 - val_loss: 1.2644 - learning_rate: 0.0010
Epoch 10/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.5162 - loss: 1.2536 - val_accuracy: 0.5207 - val_loss: 1.2256 - learning_rate: 0.0010
Epoch 11/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.5277 - loss: 1.2199 - val_accuracy: 0.5337 - val_loss: 1.1965 - learning_rate: 0.0010
Epoch 12/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.5423 - loss: 1.1829 - val_accuracy: 0.5384 - val_loss: 1.1812 - learning_rate: 0.0010
Epoch 13/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.5555 - loss: 1.1475 - val_accuracy: 0.5559 - val_loss: 1.1375 - learning_rate: 0.0010
Epoch 14/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.5690 - loss: 1.1160 - val_accuracy: 0.5641 - val_loss: 1.1107 - learning_rate: 0.0010
Epoch 15/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.5814 - loss: 1.0854 - val_accuracy: 0.5773 - val_loss: 1.0857 - learning_rate: 0.0010
Epoch 16/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.5906 - loss: 1.0643 - val_accuracy: 0.5907 - val_loss: 1.0600 - learning_rate: 0.0010
Epoch 17/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6013 - loss: 1.0341 - val_accuracy: 0.5948 - val_loss: 1.0467 - learning_rate: 0.0010
Epoch 18/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 147ms/step - accuracy: 0.6077 - loss: 1.0176 - val_accuracy: 0.5973 - val_loss: 1.0351 - learning_rate: 0.0010
Epoch 19/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 147ms/step - accuracy: 0.6162 - loss: 0.9988 - val_accuracy: 0.6077 - val_loss: 1.0120 - learning_rate: 0.0010
Epoch 20/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.6237 - loss: 0.9806 - val_accuracy: 0.6086 - val_loss: 1.0031 - learning_rate: 0.0010
Epoch 21/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6320 - loss: 0.9605 - val_accuracy: 0.6179 - val_loss: 0.9896 - learning_rate: 0.0010
Epoch 22/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.6491 - loss: 0.9198 - val_accuracy: 0.6305 - val_loss: 0.9526 - learning_rate: 5.0000e-04
Epoch 23/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.6655 - loss: 0.8860 - val_accuracy: 0.6407 - val_loss: 0.9288 - learning_rate: 2.5000e-04
Epoch 24/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 145ms/step - accuracy: 0.6735 - loss: 0.8675 - val_accuracy: 0.6435 - val_loss: 0.9218 - learning_rate: 1.2500e-04
Epoch 25/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 146ms/step - accuracy: 0.6794 - loss: 0.8582 - val_accuracy: 0.6477 - val_loss: 0.9169 - learning_rate: 6.2500e-05
Epoch 26/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6822 - loss: 0.8539 - val_accuracy: 0.6479 - val_loss: 0.9149 - learning_rate: 3.1250e-05
Epoch 27/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6817 - loss: 0.8516 - val_accuracy: 0.6489 - val_loss: 0.9141 - learning_rate: 1.5625e-05
Epoch 28/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6824 - loss: 0.8502 - val_accuracy: 0.6498 - val_loss: 0.9137 - learning_rate: 7.8125e-06
Epoch 29/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6833 - loss: 0.8493 - val_accuracy: 0.6492 - val_loss: 0.9135 - learning_rate: 3.9063e-06
Epoch 30/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 146ms/step - accuracy: 0.6827 - loss: 0.8499 - val_accuracy: 0.6493 - val_loss: 0.9135 - learning_rate: 1.9531e-06
Epoch 31/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6816 - loss: 0.8500 - val_accuracy: 0.6489 - val_loss: 0.9134 - learning_rate: 9.7656e-07
Epoch 32/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6824 - loss: 0.8504 - val_accuracy: 0.6493 - val_loss: 0.9134 - learning_rate: 4.8828e-07
Epoch 33/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6831 - loss: 0.8489 - val_accuracy: 0.6493 - val_loss: 0.9134 - learning_rate: 2.4414e-07
Epoch 34/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6823 - loss: 0.8502 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.2207e-07
Epoch 35/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 147ms/step - accuracy: 0.6834 - loss: 0.8483 - val_accuracy: 0.6491 - val_loss: 0.9133 - learning_rate: 6.1035e-08
Epoch 36/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6831 - loss: 0.8504 - val_accuracy: 0.6491 - val_loss: 0.9133 - learning_rate: 3.0518e-08
Epoch 37/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">41s</span> 147ms/step - accuracy: 0.6818 - loss: 0.8501 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.5259e-08
Epoch 38/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 147ms/step - accuracy: 0.6837 - loss: 0.8487 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 7.6294e-09
Epoch 39/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 149ms/step - accuracy: 0.6810 - loss: 0.8501 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 3.8147e-09
Epoch 40/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 149ms/step - accuracy: 0.6826 - loss: 0.8498 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.9073e-09
Epoch 41/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">83s</span> 155ms/step - accuracy: 0.6824 - loss: 0.8495 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 9.5367e-10
Epoch 42/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">80s</span> 148ms/step - accuracy: 0.6827 - loss: 0.8484 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 4.7684e-10
Epoch 43/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 149ms/step - accuracy: 0.6833 - loss: 0.8491 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 2.3842e-10
Epoch 44/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6824 - loss: 0.8504 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.1921e-10
Epoch 45/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">44s</span> 157ms/step - accuracy: 0.6824 - loss: 0.8497 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 5.9605e-11
Epoch 46/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 148ms/step - accuracy: 0.6825 - loss: 0.8510 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 2.9802e-11
Epoch 47/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6808 - loss: 0.8492 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.4901e-11
Epoch 48/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 148ms/step - accuracy: 0.6838 - loss: 0.8498 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 7.4506e-12
Epoch 49/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">42s</span> 147ms/step - accuracy: 0.6827 - loss: 0.8495 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 3.7253e-12
Epoch 50/50
<span class="ansi-bold">282/282</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">82s</span> 148ms/step - accuracy: 0.6811 - loss: 0.8501 - val_accuracy: 0.6492 - val_loss: 0.9133 - learning_rate: 1.8626e-12
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">2s</span> 2s/step
Q: 625+6573 | True: 7198 | Pred: 7180
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 1913+6609 | True: 8522 | Pred: 8518
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 625+5616 | True: 6241 | Pred: 6267
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 1949+1921 | True: 3870 | Pred: 3896
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 50ms/step
Q: 8073-5143 | True: 2930 | Pred: 2900
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 35ms/step
Q: 8811+6100 | True: 14911 | Pred: 14918
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 34ms/step
Q: 9097+8056 | True: 17153 | Pred: 17141
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 2868+1374 | True: 4242 | Pred: 4249
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 33ms/step
Q: 6211-9560 | True: -3349 | Pred: -3379
<span class="ansi-bold">1/1</span> <span class="ansi-green-fg"></span> <span class="ansi-bold">0s</span> 36ms/step
Q: 4030+7788 | True: 11818 | Pred: 11849
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-2:-A-language-translation-model-with-attention">Part 2: A language translation model with attention<a class="anchor-link" href="#Part-2:-A-language-translation-model-with-attention"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="0">
<li>Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">tutorial</a>. This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-0)"><strong>Answer 0)</strong><a class="anchor-link" href="#Answer-0)"></a></h1><p>Bahdanau Attention:</p>
<p>Additive Attention: Combines the decoders hidden state and encoders outputs using a feed forward neural network with non-linearity (for example tanh).</p>
<p>Each alignment score is calculated individually for each source word.</p>
<p>It combines information from both the encoder and decoder hidden states via a concatenation operation and a learned transformation.
The non linear transformation allows for flexible learning of complex dependencies.</p>
<p>This makes Bahdanau attention more expressive and capable of learning nuanced alignments.</p>
<p>Luong Attention:</p>
<p>Multiplicative Attention: Uses dot products between the decoder hidden state and encoder outputs.</p>
<p>Provides global and local attention options:</p>
<p>Global focuses on the full input sequence.
Local limits the focus to a subset of the input sequence.
Computationally more efficient than Bahdanau.</p>
<p>The dot product measures the similarity between the encoder and decoder hidden states.</p>
<p>No additional parameters are learned for alignment scoring, making this mechanism simpler and computationally efficient.</p>
<p>The attention mechanisms ability to learn is limited compared to Bahdanau attention because there is no transformation or added flexibility.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.a) Using <code>!wget</code>, <code>!unzip</code> , download and extract the <a href="https://www.manythings.org/anki/">hebrew-english</a> sentence pairs text file to the Colab <code>content/</code>  folder (or local folder if not using Colab).
1.b) The <code>heb.txt</code> must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-1)"><strong>Answer 1)</strong><a class="anchor-link" href="#Answer-1)"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Step 1.a: Download and extract the file</span>
<span class="k">def</span> <span class="nf">download_and_extract_data</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">os</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">"heb-eng.zip"</span><span class="p">):</span>
        <span class="o">!</span>wget<span class="w"> </span>https://www.manythings.org/anki/heb-eng.zip

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">"heb.txt"</span><span class="p">):</span>
        <span class="o">!</span>unzip<span class="w"> </span>heb-eng.zip

<span class="c1"># Call the function to ensure data is downloaded and extracted</span>
<span class="n">download_and_extract_data</span><span class="p">()</span>

<span class="c1"># Step 1.b: Parse and clean the data</span>
<span class="k">def</span> <span class="nf">parse_and_clean_data</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Parse and clean the heb.txt file.</span>
<span class="sd">    - Remove punctuation and convert text to lowercase.</span>
<span class="sd">    - Split into sentence pairs.</span>
<span class="sd">    - Return processed data.</span>
<span class="sd">    """</span>
    <span class="kn">import</span> <span class="nn">string</span>

    <span class="c1"># Read the file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Split lines into sentence pairs (Hebrew-English  English-Hebrew)</span>
    <span class="n">sentence_pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

    <span class="c1"># Swap the order of Hebrew and English</span>
    <span class="n">sentence_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">sentence_pairs</span><span class="p">]</span>

    <span class="c1"># Define a function to clean text</span>
    <span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">""</span><span class="p">,</span> <span class="s2">""</span><span class="p">,</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">text</span>

    <span class="c1"># Clean both English and Hebrew sentences</span>
    <span class="n">cleaned_pairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">clean_text</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">clean_text</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">sentence_pairs</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">cleaned_pairs</span>

<span class="c1"># Parse and clean the data</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s2">"heb.txt"</span>
<span class="n">cleaned_data</span> <span class="o">=</span> <span class="n">parse_and_clean_data</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>

<span class="c1"># Display a sample of the cleaned data</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Hebrew: </span><span class="si">{</span><span class="n">cleaned_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> | English: </span><span class="si">{</span><span class="n">cleaned_data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total sentence pairs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cleaned_data</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Hebrew:  | English: go
Hebrew:  | English: hi
Hebrew:  | English: hi
Hebrew:  | English: run
Hebrew:  | English: run
Total sentence pairs: 128133
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same <code>eng_prefixes</code> filter to limit the train/test data.<br/>
2.b) Evaluate your trained model randomly on 20 sentences.<br/>
2.c) Show the attention plot for 5 random sentences.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-2)"><strong>Answer 2)</strong><a class="anchor-link" href="#Answer-2)"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="2a-+-2b"><strong>2a + 2b</strong><a class="anchor-link" href="#2a-+-2b"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Parameters</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Helper Functions</span>
<span class="k">def</span> <span class="nf">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">m </span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">s'</span>

<span class="k">def</span> <span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">estimated_total</span> <span class="o">=</span> <span class="n">elapsed</span> <span class="o">/</span> <span class="n">percent</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="n">estimated_total</span> <span class="o">-</span> <span class="n">elapsed</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">elapsed</span><span class="p">)</span><span class="si">}</span><span class="s1"> (- </span><span class="si">{</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">remaining</span><span class="p">)</span><span class="si">}</span><span class="s1">)'</span>

<span class="c1"># Language Class</span>
<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Count SOS and EOS</span>

    <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Preprocess Data</span>
<span class="k">def</span> <span class="nf">prepareData</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">pairs</span><span class="p">):</span>
    <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
    <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Read </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span><span class="si">}</span><span class="s2"> sentence pairs"</span><span class="p">)</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Trimmed to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span><span class="si">}</span><span class="s2"> sentence pairs"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Counted words:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>

<span class="c1"># Encoder Model</span>
<span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

<span class="c1"># Decoder with Attention</span>
<span class="k">class</span> <span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span> <span class="o">=</span> <span class="n">dropout_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">max_length</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">attn_applied</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attn_applied</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

<span class="c1"># Training</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">target_length</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
        <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]])</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

    <span class="n">use_teacher_forcing</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">use_teacher_forcing</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">target_length</span>

<span class="c1"># Evaluation</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
        <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
            <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
            <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">+=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]])</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

        <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">decoded_words</span>

<span class="c1"># Helper Functions</span>
<span class="k">def</span> <span class="nf">tensorFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>
    <span class="n">indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Word-Level Accuracy</span>
<span class="k">def</span> <span class="nf">compute_word_accuracy</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="n">total_words</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct_words</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_sentence</span><span class="p">,</span> <span class="n">target_sentence</span> <span class="o">=</span> <span class="n">pair</span>
        <span class="n">predicted_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">predicted_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">predicted_words</span> <span class="k">if</span> <span class="n">word</span> <span class="o">!=</span> <span class="s1">'&lt;EOS&gt;'</span><span class="p">]</span>
        <span class="n">target_words</span> <span class="o">=</span> <span class="n">target_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">pred_word</span><span class="p">,</span> <span class="n">ref_word</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_words</span><span class="p">,</span> <span class="n">target_words</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pred_word</span> <span class="o">==</span> <span class="n">ref_word</span><span class="p">:</span>
                <span class="n">correct_words</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">total_words</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_words</span> <span class="o">/</span> <span class="n">total_words</span> <span class="k">if</span> <span class="n">total_words</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word-Level Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="c1"># Prepare Data</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"i am happy"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"i am tired"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"he is tall"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"she is short"</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">'heb'</span><span class="p">,</span> <span class="s1">'eng'</span><span class="p">,</span> <span class="n">pairs</span><span class="p">)</span>

<span class="c1"># Initialize Models</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>

<span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="c1"># Train the Model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input: </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Target: </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">output_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted: </span><span class="si">{</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Compute Accuracy</span>
<span class="n">compute_word_accuracy</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Read 4 sentence pairs
Trimmed to 4 sentence pairs
Counted words:
heb 9
eng 11
Epoch 1, Loss: 1.2114
Epoch 2, Loss: 1.1712
Epoch 3, Loss: 2.3316
Epoch 4, Loss: 2.2807
Epoch 5, Loss: 1.7591
Epoch 6, Loss: 2.2340
Epoch 7, Loss: 2.1709
Epoch 8, Loss: 2.1460
Epoch 9, Loss: 1.7260
Epoch 10, Loss: 2.0495
Epoch 11, Loss: 2.0102
Epoch 12, Loss: 1.6696
Epoch 13, Loss: 1.6190
Epoch 14, Loss: 1.5779
Epoch 15, Loss: 1.8632
Epoch 16, Loss: 1.5627
Epoch 17, Loss: 1.5194
Epoch 18, Loss: 1.4684
Epoch 19, Loss: 1.6803
Epoch 20, Loss: 1.6206
Epoch 21, Loss: 1.5526
Epoch 22, Loss: 1.3337
Epoch 23, Loss: 1.4434
Epoch 24, Loss: 1.3909
Epoch 25, Loss: 1.3343
Epoch 26, Loss: 1.2393
Epoch 27, Loss: 1.2152
Epoch 28, Loss: 1.1730
Epoch 29, Loss: 1.1070
Epoch 30, Loss: 0.9580
Epoch 31, Loss: 0.8914
Epoch 32, Loss: 0.8458
Epoch 33, Loss: 0.9216
Epoch 34, Loss: 0.8605
Epoch 35, Loss: 0.8575
Epoch 36, Loss: 0.7833
Epoch 37, Loss: 0.7269
Epoch 38, Loss: 0.6883
Epoch 39, Loss: 0.6661
Epoch 40, Loss: 0.6270
Epoch 41, Loss: 0.5988
Epoch 42, Loss: 0.5478
Epoch 43, Loss: 0.5000
Epoch 44, Loss: 0.4756
Epoch 45, Loss: 0.4746
Epoch 46, Loss: 0.4351
Epoch 47, Loss: 0.4019
Epoch 48, Loss: 0.3908
Epoch 49, Loss: 0.3729
Epoch 50, Loss: 0.3802
Input:  
Target: i am happy
Predicted: i am tired &lt;EOS&gt;
Input:  
Target: i am tired
Predicted: i am tired &lt;EOS&gt;
Input:  
Target: he is tall
Predicted: he is tall &lt;EOS&gt;
Input:  
Target: she is short
Predicted: she is short &lt;EOS&gt;
Word-Level Accuracy: 0.9167
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[38]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>0.9166666666666666</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="2c"><strong>2c</strong><a class="anchor-link" href="#2c"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Function to visualize attention</span>
<span class="k">def</span> <span class="nf">show_attention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">):</span>
    <span class="c1"># Ensure attentions is 2D</span>
    <span class="k">if</span> <span class="n">attentions</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="n">attentions</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add a dimension if necessary</span>
    <span class="n">attentions</span> <span class="o">=</span> <span class="n">attentions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Convert to numpy array</span>

    <span class="c1"># Crop the attention matrix to match the input and output lengths</span>
    <span class="n">cropped_attentions</span> <span class="o">=</span> <span class="n">attentions</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">),</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">])]</span>

    <span class="c1"># Reverse each word in the input sentence for proper Hebrew display</span>
    <span class="n">input_labels</span> <span class="o">=</span> <span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">]</span>
    <span class="n">reversed_input_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">word</span><span class="p">))</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_labels</span><span class="p">]</span>  <span class="c1"># Reverse the characters of each word</span>

    <span class="c1"># Plot the attention matrix</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">cropped_attentions</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'bone'</span><span class="p">)</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

    <span class="c1"># Set up axes</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reversed_input_labels</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">reversed_input_labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>  <span class="c1"># Display reversed words</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Function to evaluate and show attention for a single sentence</span>
<span class="k">def</span> <span class="nf">evaluate_and_show_attention</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
        <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
            <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
            <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">+=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

        <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attentions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">attentions</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">data</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">attentions</span> <span class="o">=</span> <span class="n">attentions</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">decoded_words</span><span class="p">),</span> <span class="p">:</span><span class="n">input_length</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Input Sentence: </span><span class="si">{</span><span class="n">sentence</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Output Sentence: </span><span class="si">{</span><span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">decoded_words</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="n">show_attention</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">decoded_words</span><span class="p">,</span> <span class="n">attentions</span><span class="p">)</span>

<span class="c1"># Generate attention plots for 5 random sentences</span>
<span class="k">def</span> <span class="nf">show_attention_for_random_sentences</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">pair</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Example </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">:'</span><span class="p">)</span>
        <span class="n">evaluate_and_show_attention</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>

<span class="c1"># Display attention plots for 5 random sentences</span>
<span class="n">show_attention_for_random_sentences</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Example 1:
Input Sentence:  
Output Sentence: he is tall &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Example 2:
Input Sentence:  
Output Sentence: i am tired &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Example 3:
Input Sentence:  
Output Sentence: he is tall &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Example 4:
Input Sentence:  
Output Sentence: he is tall &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Example 5:
Input Sentence:  
Output Sentence: i am tired &lt;EOS&gt;
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="3">
<li>Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-3)"><strong>Answer 3)</strong><a class="anchor-link" href="#Answer-3)"></a></h1><p>Performance:</p>
<p>The model has limitations that affect its performance. While it may perform reasonably well on sentences within the filtered training data (eng_prefixes), it struggles to generalize to unseen sentence structures or words, as the vocabulary and diversity are restricted by the filter. Additionally, its limited size and training data may hinder its ability to capture complex linguistic relationships, leading to suboptimal translations for longer or more diverse sentences. Thus, the models performance is acceptable within the constraints of its training data but is inadequate for broader, real-world use cases.</p>
<p>Limitations:</p>
<p>The model has several limitations. Its vocabulary and linguistic diversity are restricted by the eng_prefixes filter, which limits its ability to generalize to sentences outside the training data. It also struggles with longer or complex sentences due to the fixed MAX_LENGTH parameter and the relatively small hidden size, which constrain its capacity to handle complex linguistic patterns. Furthermore, the dataset may not provide sufficient examples for effective training, and the lack of advanced techniques like pretraining or larger architectures reduces its overall performance. These constraints make the model suitable for basic translations but inadequate for more diverse or nuanced tasks.</p>
<p>Improvements:</p>
<ol>
<li>Expand the Dataset:</li>
</ol>
<p>Use a larger and more diverse dataset without filtering too strictly by prefixes to increase vocabulary and linguistic diversity.</p>
<ol start="2">
<li>Increase Model Capacity:</li>
</ol>
<p>Increase the hidden size or use more advanced architectures like Transformer based models for better handling of complex linguistic patterns.</p>
<ol start="3">
<li>Regularization and Optimization:</li>
</ol>
<p>Apply techniques like gradient clipping, or better optimizers to stabilize training and prevent overfitting.</p>
<ol start="4">
<li>Data Augmentation:</li>
</ol>
<p>Using techniques like back translation to create additional training data, further improving the models generalization.</p>
<ol start="5">
<li>Incorporate Pretrained Embeddings:</li>
</ol>
<p>Use pretrained word embeddings for Hebrew and English to provide the model with richer word representations.</p>
<ol start="6">
<li>Increase Computational Resources:</li>
</ol>
<p>Train the model for more epochs to ensure better convergence.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="4">
<li>Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Answer-4)"><strong>Answer 4)</strong><a class="anchor-link" href="#Answer-4)"></a></h1><p>Explanation of the Improvements:</p>
<p>The improved model performed better because of its larger capacity, diverse dataset, and the use of the Adam optimizer. Additionally, I increased the maximum sentence length to 15 words, allowing for more complex and realistic sentence pairs in training. The larger hidden size allowed the model to capture more nuanced relationships between input and output sequences, while the Adam optimizer improved convergence, reducing the chances of getting stuck in poor local minima.</p>
<p>The expanded dataset introduced variability and complexity, which pushed the improved model to learn generalizable patterns instead of memorizing the data. While both models achieved perfect accuracy on their respective datasets, the improved model is better equipped to generalize to unseen examples due to its enhancements.</p>
<p>Word-Level Accuracy of the model in Q2: 0.9167
Word-Level Accuracy of the current model: 1.0</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>



<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># Increased to allow longer sentences</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># Increased hidden size for better capacity</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Helper Functions</span>
<span class="k">def</span> <span class="nf">asMinutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">m </span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">s'</span>

<span class="k">def</span> <span class="nf">timeSince</span><span class="p">(</span><span class="n">since</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">since</span>
    <span class="n">estimated_total</span> <span class="o">=</span> <span class="n">elapsed</span> <span class="o">/</span> <span class="n">percent</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="n">estimated_total</span> <span class="o">-</span> <span class="n">elapsed</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">elapsed</span><span class="p">)</span><span class="si">}</span><span class="s1"> (- </span><span class="si">{</span><span class="n">asMinutes</span><span class="p">(</span><span class="n">remaining</span><span class="p">)</span><span class="si">}</span><span class="s1">)'</span>

<span class="c1"># Language Class</span>
<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Count SOS and EOS</span>

    <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Preprocess Data</span>
<span class="k">def</span> <span class="nf">prepareData</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">,</span> <span class="n">pairs</span><span class="p">):</span>
    <span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang1</span><span class="p">)</span>
    <span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="n">lang2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Read </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span><span class="si">}</span><span class="s2"> sentence pairs"</span><span class="p">)</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Trimmed to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span><span class="si">}</span><span class="s2"> sentence pairs"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_lang</span><span class="o">.</span><span class="n">addSentence</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Counted words:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span>

<span class="c1"># Encoder Model</span>
<span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

<span class="c1"># Decoder with Attention</span>
<span class="k">class</span> <span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span> <span class="o">=</span> <span class="n">dropout_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">max_length</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">attn_applied</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attn_applied</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>

    <span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

<span class="c1"># Training</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">target_length</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
        <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]])</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

    <span class="n">use_teacher_forcing</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">use_teacher_forcing</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">target_length</span>

<span class="c1"># Evaluation</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
        <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>

        <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
            <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
            <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">+=</span> <span class="n">encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]])</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

        <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">decoded_words</span>

<span class="c1"># Helper Functions</span>
<span class="k">def</span> <span class="nf">tensorFromSentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span>
    <span class="n">indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Word-Level Accuracy</span>
<span class="k">def</span> <span class="nf">compute_word_accuracy</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">):</span>
    <span class="n">total_words</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct_words</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_sentence</span><span class="p">,</span> <span class="n">target_sentence</span> <span class="o">=</span> <span class="n">pair</span>
        <span class="n">predicted_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">predicted_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">predicted_words</span> <span class="k">if</span> <span class="n">word</span> <span class="o">!=</span> <span class="s1">'&lt;EOS&gt;'</span><span class="p">]</span>
        <span class="n">target_words</span> <span class="o">=</span> <span class="n">target_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">pred_word</span><span class="p">,</span> <span class="n">ref_word</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_words</span><span class="p">,</span> <span class="n">target_words</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pred_word</span> <span class="o">==</span> <span class="n">ref_word</span><span class="p">:</span>
                <span class="n">correct_words</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">total_words</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_words</span> <span class="o">/</span> <span class="n">total_words</span> <span class="k">if</span> <span class="n">total_words</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Word-Level Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="c1"># Expanded Dataset</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"i am happy"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"i am tired"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"he is tall"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">"she is short"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"  "</span><span class="p">,</span> <span class="s2">"i love learning"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"  "</span><span class="p">,</span> <span class="s2">"you are very smart"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"   "</span><span class="p">,</span> <span class="s2">"she lives in the big city"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"  "</span><span class="p">,</span> <span class="s2">"i want to eat"</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"  "</span><span class="p">,</span> <span class="s2">"they are walking in the forest"</span><span class="p">]</span>
<span class="p">]</span>

<span class="c1"># Prepare Data</span>
<span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="s1">'heb'</span><span class="p">,</span> <span class="s1">'eng'</span><span class="p">,</span> <span class="n">pairs</span><span class="p">)</span>

<span class="c1"># Initialize Models</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>

<span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># Use Adam optimizer</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="c1"># Train the Model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">target_tensor</span> <span class="o">=</span> <span class="n">tensorFromSentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Input: </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Target: </span><span class="si">{</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">output_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Predicted: </span><span class="si">{</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Compute Accuracy</span>
<span class="n">compute_word_accuracy</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Read 9 sentence pairs
Trimmed to 9 sentence pairs
Counted words:
heb 22
eng 28
Epoch 1, Loss: 3.4166
Epoch 2, Loss: 2.7168
Epoch 3, Loss: 1.1721
Epoch 4, Loss: 1.6244
Epoch 5, Loss: 0.9653
Epoch 6, Loss: 0.5052
Epoch 7, Loss: 0.1915
Epoch 8, Loss: 0.1022
Epoch 9, Loss: 0.0573
Epoch 10, Loss: 0.0395
Epoch 11, Loss: 0.0300
Epoch 12, Loss: 0.0245
Epoch 13, Loss: 0.0205
Epoch 14, Loss: 0.0175
Epoch 15, Loss: 0.0164
Epoch 16, Loss: 0.0144
Epoch 17, Loss: 0.0130
Epoch 18, Loss: 0.0122
Epoch 19, Loss: 0.0106
Epoch 20, Loss: 0.0103
Epoch 21, Loss: 0.0094
Epoch 22, Loss: 0.0087
Epoch 23, Loss: 0.0080
Epoch 24, Loss: 0.0075
Epoch 25, Loss: 0.0073
Epoch 26, Loss: 0.0064
Epoch 27, Loss: 0.0062
Epoch 28, Loss: 0.0058
Epoch 29, Loss: 0.0055
Epoch 30, Loss: 0.0052
Epoch 31, Loss: 0.0049
Epoch 32, Loss: 0.0047
Epoch 33, Loss: 0.0046
Epoch 34, Loss: 0.0045
Epoch 35, Loss: 0.0042
Epoch 36, Loss: 0.0038
Epoch 37, Loss: 0.0037
Epoch 38, Loss: 0.0035
Epoch 39, Loss: 0.0036
Epoch 40, Loss: 0.0033
Epoch 41, Loss: 0.0033
Epoch 42, Loss: 0.0032
Epoch 43, Loss: 0.0029
Epoch 44, Loss: 0.0028
Epoch 45, Loss: 0.0028
Epoch 46, Loss: 0.0028
Epoch 47, Loss: 0.0025
Epoch 48, Loss: 0.0024
Epoch 49, Loss: 0.0024
Epoch 50, Loss: 0.0024
Input:  
Target: i am happy
Predicted: i am happy &lt;EOS&gt;
Input:  
Target: i am tired
Predicted: i am tired &lt;EOS&gt;
Input:  
Target: he is tall
Predicted: he is tall &lt;EOS&gt;
Input:  
Target: she is short
Predicted: she is short &lt;EOS&gt;
Input:   
Target: i love learning
Predicted: i love learning &lt;EOS&gt;
Input:   
Target: you are very smart
Predicted: you are very smart &lt;EOS&gt;
Input:    
Target: she lives in the big city
Predicted: she lives in the big city &lt;EOS&gt;
Input:   
Target: i want to eat
Predicted: i want to eat &lt;EOS&gt;
Input:   
Target: they are walking in the forest
Predicted: they are walking in the forest &lt;EOS&gt;
Word-Level Accuracy: 1.0000
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[56]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>1.0</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># use the following parameters:</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### ANSWERS ABOVE: CODE + EXPLANATIONS</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
